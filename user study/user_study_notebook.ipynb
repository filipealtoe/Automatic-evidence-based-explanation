{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:46.484158Z",
     "start_time": "2025-02-02T23:21:46.471147Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import stats"
   ],
   "outputs": [],
   "execution_count": 216
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:46.497568Z",
     "start_time": "2025-02-02T23:21:46.490588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_git_root():\n",
    "    try:\n",
    "        git_root = subprocess.check_output(['git', 'rev-parse', '--show-toplevel'],\n",
    "                                           stderr=subprocess.STDOUT).decode().strip()\n",
    "        return Path(git_root)\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"Warning: Not in a git repository. Using current working directory.\")\n",
    "        return Path.cwd()"
   ],
   "id": "c57f3e35772a182b",
   "outputs": [],
   "execution_count": 217
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:46.826647Z",
     "start_time": "2025-02-02T23:21:46.656890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filename = 'Evaluating a Fact-Checking Process For Journalism.csv'\n",
    "output_dir = get_git_root() / 'user_study_effort'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"Created directory: {output_dir}\")\n",
    "else:\n",
    "    print(f\"Directory already exists: {output_dir}\")\n",
    "df = pd.read_csv(filename)\n",
    "print(f'Number of answers pre filtering: {len(df)}')"
   ],
   "id": "f822246d46e848e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: /Users/sergiopinto/Desktop/MemeFact/user_study_effort\n",
      "Number of answers pre filtering: 113\n"
     ]
    }
   ],
   "execution_count": 218
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:46.854463Z",
     "start_time": "2025-02-02T23:21:46.846509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# filter invalid submissions on prolific (TIME TAKEN <= 10 minutes)\n",
    "\n",
    "rejected_prolific_ids = ['676e1a07c8eaac68bfb02b3d','6701920d56778252df2b1a49','6735e4faf027b9361e838666', '5c8d01cd2edaac00169007e6', '61092e5621c9bede90eb43b1', '67701371beadf0bff4672b32', '6786b7d4ca3e75e900edb6a5', '60690d928069052871e34f25', '667583f2ad1a0accaa279c25', '66aa9bfa8baa2b88248c0ed2', '673f8b0d3dd0d3cc8ca0fe32'\n",
    "]\n",
    "df = df[~df['Please enter your prolific ID.'].isin(rejected_prolific_ids)] \n",
    "print(f'Number of answers post rejection filtering: {len(df)}')"
   ],
   "id": "679e22839bbbd4c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of answers post rejection filtering: 103\n"
     ]
    }
   ],
   "execution_count": 219
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:46.905666Z",
     "start_time": "2025-02-02T23:21:46.902608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# filter duplicate answers\n",
    "\n",
    "df = df.drop_duplicates(subset=['Please enter your prolific ID.'])\n",
    "print(f'Number of answers post duplicate filtering: {len(df)}')"
   ],
   "id": "2ea74dab1d54ce5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of answers post duplicate filtering: 103\n"
     ]
    }
   ],
   "execution_count": 220
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:46.956878Z",
     "start_time": "2025-02-02T23:21:46.952811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Number of columns: {len(df)}')\n",
    "new_col_names = {\n",
    "    'Timestamp': 'timestamp',\n",
    "    'I hereby confirm that I have read the Data Collection & Privacy Information and consent to take part in this study by selecting the \\'I agree\\' option below:': 'auth',\n",
    "    'Please enter your prolific ID.': 'prolific_id'\n",
    "}\n",
    "df = df.rename(columns=new_col_names)"
   ],
   "id": "3afb157fe62f76c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 103\n"
     ]
    }
   ],
   "execution_count": 221
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:47.009868Z",
     "start_time": "2025-02-02T23:21:47.003419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# participant private data\n",
    "\n",
    "new_col_names = {\n",
    "    'Please indicate your age group.': 'age_group',\n",
    "    'Please indicate your proficiency in English language comprehension.': 'english_level',\n",
    "    'Please indicate your highest completed level of education.': 'education_level',\n",
    "    'Please indicate your political orientation.': 'political_orientation',\n",
    "    'Please indicate your years of experience in journalistic fact checking and verification work.': 'fc_years_of_experience',\n",
    "    'Please provide your email address if you\\'d like to be contacted for future studies.': 'email'\n",
    "}\n",
    "columns_to_select = ['prolific_id'] + list(new_col_names.keys())\n",
    "participants_data = df[columns_to_select].rename(columns=new_col_names)\n",
    "output_path = f\"{output_dir}/participants_data.csv\"\n",
    "participants_data.to_csv(output_path, index=False)"
   ],
   "id": "6c5fb7b334e39e99",
   "outputs": [],
   "execution_count": 222
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:47.059475Z",
     "start_time": "2025-02-02T23:21:47.053775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# participants feedback\n",
    "\n",
    "new_col_names = {\n",
    "    'Optional: Please share any additional thoughts or suggestions about the fact-checking process presented or any other feedback you may want to disclose.': 'process_feedback',\n",
    "    'Optional: Please share any additional observations, suggestions, or concerns about the questions and their justifications. Your feedback will help improve the fact-checking process.': 'claim_decomposition_feedback',\n",
    "    'Optional: Please share any additional observations, suggestions, or concerns about the question explanations and verdicts. Your feedback will help improve the fact-checking process.': 'evidence_synthesis_feedback',\n",
    "    'Optional: Please share any additional observations, suggestions, or concerns about the summary explanation and claim\\'s verdict. Your feedback will help improve the fact-checking process.': 'final_conclusion_feedback',\n",
    "    'Do you have any comments or suggestions about this survey? Your feedback will help us improve future studies.': 'user_study_feedback'\n",
    "}\n",
    "columns_to_select = ['prolific_id'] + list(new_col_names.keys())\n",
    "participants_feedback = df[columns_to_select].rename(columns=new_col_names)\n",
    "output_path = f\"{output_dir}/participants_feedback.csv\"\n",
    "participants_feedback.to_csv(output_path, index=False)"
   ],
   "id": "86526b7b047d4851",
   "outputs": [],
   "execution_count": 223
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:47.106246Z",
     "start_time": "2025-02-02T23:21:47.101821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# process evaluation\n",
    "\n",
    "new_col_names = {\n",
    "    'How would you assess the explainability of the fact-checking process\\'s intermediate steps in terms of understanding how claims are broken down and analyzed to reach verdicts and generate explanations?': 'process_explainability',\n",
    "    'How would you assess the transparency of the process in demonstrating the progression from input claim to verdict and explanation summary?': 'process_transparency',\n",
    "    'How would you assess the transparency in how sources are selected and validated?': 'sources_transparency',\n",
    "    'How would you assess the level of trust that this fact-checking process inspires?': 'process_level_of_trust',\n",
    "    'How would you assess the credibility of this fact-checking process compared to existing fact-checking approaches you are familiar with? ': 'process_credibility'\n",
    "}\n",
    "columns_to_select = ['prolific_id'] + list(new_col_names.keys())\n",
    "process_evaluation = df[columns_to_select].rename(columns=new_col_names)\n",
    "output_path = f\"{output_dir}/process_evaluation.csv\"\n",
    "process_evaluation.to_csv(output_path, index=False)"
   ],
   "id": "4d02d2d8b72b8cc8",
   "outputs": [],
   "execution_count": 224
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:47.154113Z",
     "start_time": "2025-02-02T23:21:47.148127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# cd artifacts evaluation\n",
    "\n",
    "new_col_names = {\n",
    "    'How thoroughly do the decomposing questions cover all aspects of the claim that need verification?': 'questions_coverage',\n",
    "    'How relevant are the additional aspects introduced by the decomposing questions for verifying the claim\\'s accuracy?': 'questions_relevance',\n",
    "    'How well are the questions formulated to allow for clear \"Yes\", \"No\", or \"Unverified\" verdicts based on available evidence?': 'questions_formulation',\n",
    "    'How well do the justifications explain the relevance of the questions for verifying the claim\\'s accuracy?': 'justifications_explainability'\n",
    "}\n",
    "\n",
    "rename_mapping = {}\n",
    "\n",
    "for old_col, new_base in new_col_names.items():\n",
    "    rename_mapping[old_col] = f\"{new_base}_claim1\"\n",
    "\n",
    "for i in range(1, 5):\n",
    "    for old_col, new_base in new_col_names.items():\n",
    "        old_col_with_suffix = f\"{old_col}.{i}\"\n",
    "        rename_mapping[old_col_with_suffix] = f\"{new_base}_claim{i+1}\"\n",
    "\n",
    "columns_to_select = ['prolific_id'] + list(rename_mapping.keys())\n",
    "cd_artifacts_evaluation = df[columns_to_select].rename(columns=rename_mapping)\n",
    "\n",
    "output_path = f\"{output_dir}/cd_artifacts_evaluation.csv\"\n",
    "cd_artifacts_evaluation.to_csv(output_path, index=False)"
   ],
   "id": "2e1b81827bcf87f9",
   "outputs": [],
   "execution_count": 225
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:47.203464Z",
     "start_time": "2025-02-02T23:21:47.198425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# es artifacts evaluation\n",
    "\n",
    "new_col_names = {\n",
    "   'How relevant are the explanations to answering their respective questions?': 'explanations_relevance',\n",
    "   'How effective are the explanations at reaching conclusions that respond to the questions?': 'explanations_effectiveness', \n",
    "   'How logically do the verdicts follow from the evidence in the explanations given the questions?': 'verdicts_logical_connection'\n",
    "}\n",
    "\n",
    "rename_mapping = {}\n",
    "\n",
    "for old_col, new_base in new_col_names.items():\n",
    "   rename_mapping[old_col] = f\"{new_base}_claim1\"\n",
    "\n",
    "for i in range(1, 5):\n",
    "   for old_col, new_base in new_col_names.items():\n",
    "       old_col_with_suffix = f\"{old_col}.{i}\"\n",
    "       rename_mapping[old_col_with_suffix] = f\"{new_base}_claim{i+1}\"\n",
    "\n",
    "columns_to_select = ['prolific_id'] + list(rename_mapping.keys())\n",
    "es_artifacts_evaluation = df[columns_to_select].rename(columns=rename_mapping)\n",
    "\n",
    "output_path = f\"{output_dir}/es_artifacts_evaluation.csv\"\n",
    "es_artifacts_evaluation.to_csv(output_path, index=False)"
   ],
   "id": "891265ac02131619",
   "outputs": [],
   "execution_count": 226
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:47.290869Z",
     "start_time": "2025-02-02T23:21:47.285184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# fc artifacts evaluation\n",
    "\n",
    "new_col_names = {\n",
    "   'How thoroughly does the summary explanation cover all aspects of the claim that need verification?': 'summary_coverage',\n",
    "   'How well does the summary explanation support the final verdict given to the claim?': 'summary_verdict_support',\n",
    "   'How factually aligned is Summary 1 with Summary 2?': 'summaries_allignment',\n",
    "   'As a journalist, which summary would you consider more credible and rigorous for fact-checking the claim?': 'summary_choice'\n",
    "}\n",
    "\n",
    "rename_mapping = {}\n",
    "\n",
    "for old_col, new_base in new_col_names.items():\n",
    "   rename_mapping[old_col] = f\"{new_base}_claim1\"\n",
    "\n",
    "for i in range(1, 5):\n",
    "   for old_col, new_base in new_col_names.items():\n",
    "       old_col_with_suffix = f\"{old_col}.{i}\"\n",
    "       rename_mapping[old_col_with_suffix] = f\"{new_base}_claim{i+1}\"\n",
    "\n",
    "columns_to_select = ['prolific_id'] + list(rename_mapping.keys())\n",
    "fc_artifacts_evaluation = df[columns_to_select].rename(columns=rename_mapping)\n",
    "\n",
    "output_path = f\"{output_dir}/fc_artifacts_evaluation.csv\"\n",
    "fc_artifacts_evaluation.to_csv(output_path, index=False)"
   ],
   "id": "d8e2e4c7b7e0afd3",
   "outputs": [],
   "execution_count": 227
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:47.318403Z",
     "start_time": "2025-02-02T23:21:47.313879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "claims_data = [\n",
    "   {\n",
    "       'number': 1,\n",
    "       'text': 'Says Ford agreed to invest $900 million at an Ohio plant because Donald Trump lowered taxes and is now moving the project to Mexico because Joe Biden is increasing taxes.',\n",
    "       'political_stance': 'pro_republican',\n",
    "       'evidence_id': '-1365092868303902720'\n",
    "   },\n",
    "   {\n",
    "       'number': 2,\n",
    "       'text': 'The Biden administration inherited gains of 50,000 jobs a month. We\\'re now finally back to 500,000 jobs a month. We inherited a country where 4,000 people a day were dying from Covid. That\\'s now down 75%.',\n",
    "       'political_stance': 'pro_democrat', \n",
    "       'evidence_id': '5948245359632679936'\n",
    "   },\n",
    "   {\n",
    "       'number': 3,\n",
    "       'text': 'Officials recommend that women who get one of these (COVID-19) shots should absolutely not get pregnant for at least the first two months after they\\'ve been injected.',\n",
    "       'political_stance': 'neutral',\n",
    "       'evidence_id': '1015833665715298432'\n",
    "   },\n",
    "   {\n",
    "       'number': 4,\n",
    "       'text': 'Joe Biden and Kamala Harris government-run health care plan could lead to hospitals being closed, put Medicare coverage at risk, and give benefits to illegal immigrants.',\n",
    "       'political_stance': 'pro_republican',\n",
    "       'evidence_id': '7928069865906505728'\n",
    "   },\n",
    "   {\n",
    "       'number': 5,\n",
    "       'text': 'Wisconsin was the last state to start paying COVID-related federal unemployment benefits.',\n",
    "       'political_stance': 'neutral',\n",
    "       'evidence_id': '8719092942913588224'\n",
    "   }\n",
    "]\n",
    "\n",
    "claims = pd.DataFrame(claims_data)\n",
    "\n",
    "output_path = f\"{output_dir}/claims.csv\"\n",
    "claims.to_csv(output_path, index=False)"
   ],
   "id": "a187bd0221200f0b",
   "outputs": [],
   "execution_count": 228
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:47.367357Z",
     "start_time": "2025-02-02T23:21:47.364753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "processed_dir = os.path.join(output_dir, 'processed')\n",
    "if not os.path.exists(processed_dir):\n",
    "   os.makedirs(processed_dir)"
   ],
   "id": "b3e3ca81a457797c",
   "outputs": [],
   "execution_count": 229
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:47.420959Z",
     "start_time": "2025-02-02T23:21:47.413015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# process evaluations processing\n",
    "\n",
    "explainability_map = {\n",
    "    'No clear explainability': 1,\n",
    "    'Limited explainability': 2,\n",
    "    'Adequate explainability': 3,\n",
    "    'High explainability': 4,\n",
    "    'Exceptional explainability': 5\n",
    "}\n",
    "\n",
    "process_transparency_map = {\n",
    "    'No clear transparency': 1,\n",
    "    'Limited transparency': 2,\n",
    "    'Adequate transparency': 3,\n",
    "    'High transparency': 4,\n",
    "    'Exceptional transparency': 5\n",
    "}\n",
    "\n",
    "sources_transparency_map = {\n",
    "    'No clear transparency': 1,\n",
    "    'Limited transparency': 2,\n",
    "    'Adequate transparency': 3,\n",
    "    'High transparency': 4,\n",
    "    'Exceptional transparency': 5\n",
    "}\n",
    "\n",
    "trust_map = {\n",
    "    'No clear trustworthiness': 1,\n",
    "    'Limited trustworthiness': 2,\n",
    "    'Adequate trustworthiness': 3,\n",
    "    'High trustworthiness': 4,\n",
    "    'Exceptional trustworthiness': 5\n",
    "}\n",
    "\n",
    "credibility_map = {\n",
    "    'No prior experience with fact-checking systems': 0,\n",
    "    'Lower credibility': 1,\n",
    "    'Similar credibility': 2,\n",
    "    'Superior credibility': 3\n",
    "}\n",
    "\n",
    "df = pd.read_csv(f\"{output_dir}/process_evaluation.csv\")\n",
    "\n",
    "process_evaluation = df.copy()\n",
    "\n",
    "process_evaluation['process_explainability'] = process_evaluation['process_explainability'].map(explainability_map)\n",
    "process_evaluation['process_transparency'] = process_evaluation['process_transparency'].map(process_transparency_map)\n",
    "process_evaluation['sources_transparency'] = process_evaluation['sources_transparency'].map(sources_transparency_map)\n",
    "process_evaluation['process_level_of_trust'] = process_evaluation['process_level_of_trust'].map(trust_map)\n",
    "process_evaluation['process_credibility'] = process_evaluation['process_credibility'].map(credibility_map)\n",
    "\n",
    "# Save to processed directory\n",
    "output_path = os.path.join(processed_dir, 'process_evaluation_phase_1.csv')\n",
    "process_evaluation.to_csv(output_path, index=False)"
   ],
   "id": "9400f59f725771d",
   "outputs": [],
   "execution_count": 230
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:47.475580Z",
     "start_time": "2025-02-02T23:21:47.464295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# cd artifacts processing\n",
    "\n",
    "coverage_map = {\n",
    "   'No coverage': 1,\n",
    "   'Limited coverage': 2,\n",
    "   'Adequate coverage': 3, \n",
    "   'High coverage': 4,\n",
    "   'Excellent coverage': 5\n",
    "}\n",
    "\n",
    "relevance_map = {\n",
    "   'No relevance': 1,\n",
    "   'Limited relevance': 2,\n",
    "   'Adequate relevance': 3,\n",
    "   'High relevance': 4, \n",
    "   'Excellent relevance': 5\n",
    "}\n",
    "\n",
    "formulation_map = {\n",
    "   'Poor formulation': 1,\n",
    "   'Limited formulation': 2,\n",
    "   'Adequate formulation': 3,\n",
    "   'Strong formulation': 4,\n",
    "   'Excellent formulation': 5\n",
    "}\n",
    "\n",
    "justification_map = {\n",
    "   'No relevance': 1,\n",
    "   'Limited relevance': 2,\n",
    "   'Adequate relevance': 3,\n",
    "   'High relevance': 4,\n",
    "   'Excellent relevance': 5\n",
    "}\n",
    "\n",
    "cd_df = pd.read_csv(f\"{output_dir}/cd_artifacts_evaluation.csv\")\n",
    "cd_processed = cd_df.copy()\n",
    "\n",
    "for col in cd_processed.columns:\n",
    "   if 'questions_coverage' in col:\n",
    "       cd_processed[col] = cd_processed[col].map(coverage_map)\n",
    "   elif 'questions_relevance' in col:\n",
    "       cd_processed[col] = cd_processed[col].map(relevance_map)\n",
    "   elif 'questions_formulation' in col:\n",
    "       cd_processed[col] = cd_processed[col].map(formulation_map)\n",
    "   elif 'justifications_explainability' in col:\n",
    "       cd_processed[col] = cd_processed[col].map(justification_map)\n",
    "   else:\n",
    "       print(f'Not processing column: {col}')\n",
    "\n",
    "output_path = os.path.join(processed_dir, 'cd_process_phase_1.csv')\n",
    "cd_processed.to_csv(output_path, index=False)"
   ],
   "id": "69d00dc83ce72632",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not processing column: prolific_id\n"
     ]
    }
   ],
   "execution_count": 231
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:47.532322Z",
     "start_time": "2025-02-02T23:21:47.521459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# es artifacts processing\n",
    "\n",
    "relevance_map = {\n",
    "   'No relevance': 1,\n",
    "   'Limited relevance': 2,\n",
    "   'Adequate relevance': 3,\n",
    "   'High relevance': 4, \n",
    "   'Excellent relevance': 5\n",
    "}\n",
    "\n",
    "effectiveness_map = {\n",
    "   'No effectiveness': 1,\n",
    "   'Limited effectiveness': 2,\n",
    "   'Adequate effectiveness': 3,\n",
    "   'High effectiveness': 4,\n",
    "   'Excellent effectiveness': 5\n",
    "}\n",
    "\n",
    "logical_connection_map = {\n",
    "   'No logical connection': 1,\n",
    "   'Limited logical connection': 2,\n",
    "   'Adequate logical connection': 3,\n",
    "   'Strong logical connection': 4,\n",
    "   'Excellent logical connection': 5\n",
    "}\n",
    "\n",
    "es_df = pd.read_csv(f\"{output_dir}/es_artifacts_evaluation.csv\")\n",
    "es_processed = es_df.copy()\n",
    "\n",
    "for col in es_processed.columns:\n",
    "   if 'explanations_relevance' in col:\n",
    "       es_processed[col] = es_processed[col].map(relevance_map)\n",
    "   elif 'explanations_effectiveness' in col:\n",
    "       es_processed[col] = es_processed[col].map(effectiveness_map)\n",
    "   elif 'verdicts_logical_connection' in col:\n",
    "       es_processed[col] = es_processed[col].map(logical_connection_map)\n",
    "   else:\n",
    "       print(f'Not processing column: {col}')\n",
    "\n",
    "output_path = os.path.join(processed_dir, 'es_process_phase_1.csv')\n",
    "es_processed.to_csv(output_path, index=False)"
   ],
   "id": "b2452d9871394088",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not processing column: prolific_id\n"
     ]
    }
   ],
   "execution_count": 232
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:47.605575Z",
     "start_time": "2025-02-02T23:21:47.593825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# fc artifacts processing\n",
    "\n",
    "coverage_map = {\n",
    "   'No coverage': 1,\n",
    "   'Limited coverage': 2,\n",
    "   'Adequate coverage': 3,\n",
    "   'High coverage': 4, \n",
    "   'Excellent coverage': 5\n",
    "}\n",
    "\n",
    "support_map = {\n",
    "   'No support': 1,\n",
    "   'Limited support': 2,\n",
    "   'Adequate support': 3,\n",
    "   'Strong support': 4,\n",
    "   'Excellent support': 5\n",
    "}\n",
    "\n",
    "alignment_map = {\n",
    "   'Completely misaligned (Contains fabricated content that completely alters the meaning)': 1,\n",
    "   'Major misalignment (Contains factual errors that significantly misrepresent the content)': 2,\n",
    "   'Minor misalignment (Some details differ but maintains the overall message)': 3,\n",
    "   'Completely aligned (Accurately represents the same meaning and details)': 4\n",
    "}\n",
    "\n",
    "choice_map = {\n",
    "   'Summary 1 is significantly more credible and rigorous': 5,\n",
    "   'Summary 1 is somewhat more credible and rigorous': 4,\n",
    "   'Both summaries are equally credible and rigorous': 3,\n",
    "   'Summary 2 is somewhat more credible and rigorous': 2,\n",
    "   'Summary 2 is significantly more credible and rigorous': 1\n",
    "}\n",
    "\n",
    "fc_df = pd.read_csv(f\"{output_dir}/fc_artifacts_evaluation.csv\")\n",
    "fc_processed = fc_df.copy()\n",
    "\n",
    "for col in fc_processed.columns:\n",
    "   if 'summary_coverage' in col:\n",
    "       fc_processed[col] = fc_processed[col].map(coverage_map)\n",
    "   elif 'summary_verdict_support' in col:\n",
    "       fc_processed[col] = fc_processed[col].map(support_map)\n",
    "   elif 'summaries_allignment' in col:\n",
    "       fc_processed[col] = fc_processed[col].map(alignment_map)\n",
    "   elif 'summary_choice' in col:\n",
    "       fc_processed[col] = fc_processed[col].map(choice_map)\n",
    "   else:\n",
    "       print(f'Not processing column: {col}')\n",
    "\n",
    "output_path = os.path.join(processed_dir, 'fc_process_phase_1.csv')\n",
    "fc_processed.to_csv(output_path, index=False)"
   ],
   "id": "daf38ba44a102d34",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not processing column: prolific_id\n"
     ]
    }
   ],
   "execution_count": 233
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:47.678434Z",
     "start_time": "2025-02-02T23:21:47.651141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import scipy\n",
    "\n",
    "proc_df = pd.read_csv(f\"{output_dir}/processed/process_evaluation_phase_1.csv\")\n",
    "\n",
    "def get_comprehensive_stats(values, scale_max):\n",
    "   mean = np.mean(values)\n",
    "   std = np.std(values)\n",
    "   n = len(values)\n",
    "   se = scipy.stats.sem(values)\n",
    "   ci = scipy.stats.t.interval(confidence=0.95, df=n-1, loc=mean, scale=se)\n",
    "   \n",
    "   # Value distribution\n",
    "   value_counts = pd.Series(values).value_counts().sort_index()\n",
    "   percentages = (value_counts / len(values) * 100).round(2)\n",
    "   \n",
    "   return {\n",
    "       'basic_stats': {\n",
    "           'mean': mean,\n",
    "           'std': std,\n",
    "           'median': np.median(values),\n",
    "           'min': np.min(values),\n",
    "           'max': np.max(values),\n",
    "           'q1': np.percentile(values, 25),\n",
    "           'q3': np.percentile(values, 75),\n",
    "           'ci_lower': ci[0],\n",
    "           'ci_upper': ci[1],\n",
    "           'mean_percentage': (mean/scale_max)*100,\n",
    "           'n': n\n",
    "       },\n",
    "       'distribution': {\n",
    "           'values': value_counts.index.tolist(),\n",
    "           'counts': value_counts.tolist(),\n",
    "           'percentages': percentages.tolist()\n",
    "       },\n",
    "       'raw_values': values\n",
    "   }\n",
    "\n",
    "dimensions_5scale = {\n",
    "   'Process Explainability': {'col': 'process_explainability', 'stats': None},\n",
    "   'Process Transparency': {'col': 'process_transparency', 'stats': None},\n",
    "   'Sources Transparency': {'col': 'sources_transparency', 'stats': None},\n",
    "   'Process Level of Trust': {'col': 'process_level_of_trust', 'stats': None}\n",
    "}\n",
    "\n",
    "for dim_name, dim_data in dimensions_5scale.items():\n",
    "   dim_data['stats'] = get_comprehensive_stats(proc_df[dim_data['col']].values, 5)\n",
    "\n",
    "def print_basic_stats(stats, dimension, scale_max):\n",
    "   bs = stats['basic_stats']\n",
    "   print(f\"\\n{dimension} Statistics (Scale 1-{scale_max}):\")\n",
    "   print(f\"Mean: {bs['mean']:.2f} (95% CI: [{bs['ci_lower']:.2f}, {bs['ci_upper']:.2f}])\")\n",
    "   print(f\"Standard Deviation: {bs['std']:.2f}\")\n",
    "   print(f\"Median: {bs['median']:.2f}\")\n",
    "   print(f\"Min: {bs['min']:.2f}\")\n",
    "   print(f\"Max: {bs['max']:.2f}\")\n",
    "   print(f\"Q1: {bs['q1']:.2f}\")\n",
    "   print(f\"Q3: {bs['q3']:.2f}\")\n",
    "   print(f\"Mean as % of maximum: {bs['mean_percentage']:.1f}%\")\n",
    "\n",
    "def print_distribution(stats, dimension):\n",
    "   dist = stats['distribution']\n",
    "   print(f\"\\n{dimension} Value Distribution:\")\n",
    "   for val, count, pct in zip(dist['values'], dist['counts'], dist['percentages']):\n",
    "       print(f\"Value {val}: {count} occurrences ({pct:.1f}%)\")\n",
    "\n",
    "for dim_name, dim_data in dimensions_5scale.items():\n",
    "   print_basic_stats(dim_data['stats'], dim_name, 5)\n",
    "   print_distribution(dim_data['stats'], dim_name)\n",
    "\n",
    "credibility_data = proc_df['process_credibility']\n",
    "zero_count = (credibility_data == 0).sum()\n",
    "total_count = len(credibility_data)\n",
    "zero_percentage = (zero_count / total_count) * 100\n",
    "\n",
    "print(\"\\nProcess Credibility Analysis:\")\n",
    "print(f\"Participants with no prior experience: {zero_count} ({zero_percentage:.1f}%)\")\n",
    "\n",
    "non_zero_data = credibility_data[credibility_data != 0]\n",
    "if len(non_zero_data) > 0:\n",
    "   credibility_stats = get_comprehensive_stats(non_zero_data, 3)\n",
    "   bs = credibility_stats['basic_stats']\n",
    "   \n",
    "   print(\"\\nStatistics for participants with prior experience (Scale 1-3):\")\n",
    "   print(f\"N = {bs['n']} participants\")\n",
    "   print(f\"Mean: {bs['mean']:.2f} (95% CI: [{bs['ci_lower']:.2f}, {bs['ci_upper']:.2f}])\")\n",
    "   print(f\"Standard Deviation: {bs['std']:.2f}\")\n",
    "   print(f\"Median: {bs['median']:.2f}\")\n",
    "   print(f\"Min: {bs['min']:.2f}\")\n",
    "   print(f\"Max: {bs['max']:.2f}\")\n",
    "   print(f\"Q1: {bs['q1']:.2f}\")\n",
    "   print(f\"Q3: {bs['q3']:.2f}\")\n",
    "   print(f\"Mean as % of maximum: {bs['mean_percentage']:.1f}%\")\n",
    "   print_distribution(credibility_stats, \"Process Credibility (excluding no prior experience)\")"
   ],
   "id": "4df8bcd9071b48c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Process Explainability Statistics (Scale 1-5):\n",
      "Mean: 3.56 (95% CI: [3.41, 3.71])\n",
      "Standard Deviation: 0.76\n",
      "Median: 4.00\n",
      "Min: 1.00\n",
      "Max: 5.00\n",
      "Q1: 3.00\n",
      "Q3: 4.00\n",
      "Mean as % of maximum: 71.3%\n",
      "\n",
      "Process Explainability Value Distribution:\n",
      "Value 1: 1 occurrences (1.0%)\n",
      "Value 2: 7 occurrences (6.8%)\n",
      "Value 3: 35 occurrences (34.0%)\n",
      "Value 4: 53 occurrences (51.5%)\n",
      "Value 5: 7 occurrences (6.8%)\n",
      "\n",
      "Process Transparency Statistics (Scale 1-5):\n",
      "Mean: 3.53 (95% CI: [3.38, 3.68])\n",
      "Standard Deviation: 0.76\n",
      "Median: 4.00\n",
      "Min: 2.00\n",
      "Max: 5.00\n",
      "Q1: 3.00\n",
      "Q3: 4.00\n",
      "Mean as % of maximum: 70.7%\n",
      "\n",
      "Process Transparency Value Distribution:\n",
      "Value 2: 10 occurrences (9.7%)\n",
      "Value 3: 35 occurrences (34.0%)\n",
      "Value 4: 51 occurrences (49.5%)\n",
      "Value 5: 7 occurrences (6.8%)\n",
      "\n",
      "Sources Transparency Statistics (Scale 1-5):\n",
      "Mean: 3.25 (95% CI: [3.09, 3.42])\n",
      "Standard Deviation: 0.83\n",
      "Median: 3.00\n",
      "Min: 1.00\n",
      "Max: 5.00\n",
      "Q1: 3.00\n",
      "Q3: 4.00\n",
      "Mean as % of maximum: 65.0%\n",
      "\n",
      "Sources Transparency Value Distribution:\n",
      "Value 1: 2 occurrences (1.9%)\n",
      "Value 2: 15 occurrences (14.6%)\n",
      "Value 3: 46 occurrences (44.7%)\n",
      "Value 4: 35 occurrences (34.0%)\n",
      "Value 5: 5 occurrences (4.8%)\n",
      "\n",
      "Process Level of Trust Statistics (Scale 1-5):\n",
      "Mean: 3.64 (95% CI: [3.50, 3.78])\n",
      "Standard Deviation: 0.71\n",
      "Median: 4.00\n",
      "Min: 2.00\n",
      "Max: 5.00\n",
      "Q1: 3.00\n",
      "Q3: 4.00\n",
      "Mean as % of maximum: 72.8%\n",
      "\n",
      "Process Level of Trust Value Distribution:\n",
      "Value 2: 7 occurrences (6.8%)\n",
      "Value 3: 30 occurrences (29.1%)\n",
      "Value 4: 59 occurrences (57.3%)\n",
      "Value 5: 7 occurrences (6.8%)\n",
      "\n",
      "Process Credibility Analysis:\n",
      "Participants with no prior experience: 6 (5.8%)\n",
      "\n",
      "Statistics for participants with prior experience (Scale 1-3):\n",
      "N = 97 participants\n",
      "Mean: 2.22 (95% CI: [2.10, 2.33])\n",
      "Standard Deviation: 0.58\n",
      "Median: 2.00\n",
      "Min: 1.00\n",
      "Max: 3.00\n",
      "Q1: 2.00\n",
      "Q3: 3.00\n",
      "Mean as % of maximum: 73.9%\n",
      "\n",
      "Process Credibility (excluding no prior experience) Value Distribution:\n",
      "Value 1: 8 occurrences (8.2%)\n",
      "Value 2: 60 occurrences (61.9%)\n",
      "Value 3: 29 occurrences (29.9%)\n"
     ]
    }
   ],
   "execution_count": 234
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:47.787275Z",
     "start_time": "2025-02-02T23:21:47.769125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# cd artifacts statistics\n",
    "cd_df = pd.read_csv(f\"{output_dir}/processed/cd_process_phase_1.csv\")\n",
    "\n",
    "coverage_cols = [col for col in cd_df.columns if 'questions_coverage' in col]\n",
    "relevance_cols = [col for col in cd_df.columns if 'questions_relevance' in col]\n",
    "formulation_cols = [col for col in cd_df.columns if 'questions_formulation' in col]\n",
    "explainability_cols = [col for col in cd_df.columns if 'justifications_explainability' in col]\n",
    "\n",
    "def get_comprehensive_stats(df, cols):\n",
    "    all_values = df[cols].values.ravel()\n",
    "    \n",
    "    mean = np.mean(all_values)\n",
    "    std = np.std(all_values)\n",
    "    n = len(all_values)\n",
    "    se = scipy.stats.sem(all_values)\n",
    "    ci = scipy.stats.t.interval(confidence=0.95, df=n-1, loc=mean, scale=se)\n",
    "    \n",
    "    value_counts = pd.Series(all_values).value_counts().sort_index()\n",
    "    percentages = (value_counts / len(all_values) * 100).round(2)\n",
    "    \n",
    "    return {\n",
    "        'basic_stats': {\n",
    "            'mean': mean,\n",
    "            'std': std,\n",
    "            'median': np.median(all_values),\n",
    "            'min': np.min(all_values),\n",
    "            'max': np.max(all_values),\n",
    "            'q1': np.percentile(all_values, 25),\n",
    "            'q3': np.percentile(all_values, 75),\n",
    "            'ci_lower': ci[0],\n",
    "            'ci_upper': ci[1]\n",
    "        },\n",
    "        'distribution': {\n",
    "            'values': value_counts.index.tolist(),\n",
    "            'counts': value_counts.tolist(),\n",
    "            'percentages': percentages.tolist()\n",
    "        },\n",
    "        'raw_values': all_values\n",
    "    }\n",
    "\n",
    "dimensions = {\n",
    "    'Question Coverage': {'cols': coverage_cols, 'stats': None},\n",
    "    'Question Relevance': {'cols': relevance_cols, 'stats': None},\n",
    "    'Question Formulation': {'cols': formulation_cols, 'stats': None},\n",
    "    'Justification Explainability': {'cols': explainability_cols, 'stats': None}\n",
    "}\n",
    "\n",
    "for dim_name, dim_data in dimensions.items():\n",
    "    dim_data['stats'] = get_comprehensive_stats(cd_df, dim_data['cols'])\n",
    "\n",
    "claim_stats = {}\n",
    "for i in range(1, 6):\n",
    "    claim_cols = [col for col in cd_df.columns if f'claim{i}' in col]\n",
    "    claim_stats[f'claim_{i}'] = get_comprehensive_stats(cd_df, claim_cols)\n",
    "\n",
    "def print_basic_stats(stats, dimension):\n",
    "    bs = stats['basic_stats']\n",
    "    print(f\"\\n{dimension} Statistics:\")\n",
    "    print(f\"Mean: {bs['mean']:.2f} (95% CI: [{bs['ci_lower']:.2f}, {bs['ci_upper']:.2f}])\")\n",
    "    print(f\"Standard Deviation: {bs['std']:.2f}\")\n",
    "    print(f\"Median: {bs['median']:.2f}\")\n",
    "    print(f\"Min: {bs['min']:.2f}\")\n",
    "    print(f\"Max: {bs['max']:.2f}\")\n",
    "    print(f\"Q1: {bs['q1']:.2f}\")\n",
    "    print(f\"Q3: {bs['q3']:.2f}\")\n",
    "\n",
    "def print_distribution(stats, dimension):\n",
    "    dist = stats['distribution']\n",
    "    print(f\"\\n{dimension} Value Distribution:\")\n",
    "    for val, count, pct in zip(dist['values'], dist['counts'], dist['percentages']):\n",
    "        print(f\"Value {val}: {count} occurrences ({pct:.1f}%)\")\n",
    "\n",
    "for dim_name, dim_data in dimensions.items():\n",
    "    print_basic_stats(dim_data['stats'], dim_name)\n",
    "    print_distribution(dim_data['stats'], dim_name)\n",
    "\n",
    "print(\"\\nPer-Claim Statistics:\")\n",
    "for i in range(1, 6):\n",
    "    stats = claim_stats[f'claim_{i}']\n",
    "    mean = stats['basic_stats']['mean']\n",
    "    ci_lower = stats['basic_stats']['ci_lower']\n",
    "    ci_upper = stats['basic_stats']['ci_upper']\n",
    "    print(f\"\\nClaim {i}: {mean:.2f} (95% CI: [{ci_lower:.2f}, {ci_upper:.2f}])\")\n",
    "    print_distribution(stats, f\"Claim {i}\")\n",
    "\n",
    "stats_data = {\n",
    "    'dimensions': dimensions,\n",
    "    'claims': claim_stats\n",
    "}"
   ],
   "id": "acf6cc4ce37503b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question Coverage Statistics:\n",
      "Mean: 3.92 (95% CI: [3.84, 4.00])\n",
      "Standard Deviation: 0.92\n",
      "Median: 4.00\n",
      "Min: 1.00\n",
      "Max: 5.00\n",
      "Q1: 3.00\n",
      "Q3: 5.00\n",
      "\n",
      "Question Coverage Value Distribution:\n",
      "Value 1: 1 occurrences (0.2%)\n",
      "Value 2: 43 occurrences (8.3%)\n",
      "Value 3: 104 occurrences (20.2%)\n",
      "Value 4: 217 occurrences (42.1%)\n",
      "Value 5: 150 occurrences (29.1%)\n",
      "\n",
      "Question Relevance Statistics:\n",
      "Mean: 3.85 (95% CI: [3.77, 3.93])\n",
      "Standard Deviation: 0.92\n",
      "Median: 4.00\n",
      "Min: 1.00\n",
      "Max: 5.00\n",
      "Q1: 3.00\n",
      "Q3: 5.00\n",
      "\n",
      "Question Relevance Value Distribution:\n",
      "Value 1: 1 occurrences (0.2%)\n",
      "Value 2: 47 occurrences (9.1%)\n",
      "Value 3: 114 occurrences (22.1%)\n",
      "Value 4: 217 occurrences (42.1%)\n",
      "Value 5: 136 occurrences (26.4%)\n",
      "\n",
      "Question Formulation Statistics:\n",
      "Mean: 3.77 (95% CI: [3.69, 3.84])\n",
      "Standard Deviation: 0.88\n",
      "Median: 4.00\n",
      "Min: 1.00\n",
      "Max: 5.00\n",
      "Q1: 3.00\n",
      "Q3: 4.00\n",
      "\n",
      "Question Formulation Value Distribution:\n",
      "Value 1: 5 occurrences (1.0%)\n",
      "Value 2: 39 occurrences (7.6%)\n",
      "Value 3: 129 occurrences (25.1%)\n",
      "Value 4: 241 occurrences (46.8%)\n",
      "Value 5: 101 occurrences (19.6%)\n",
      "\n",
      "Justification Explainability Statistics:\n",
      "Mean: 3.88 (95% CI: [3.80, 3.95])\n",
      "Standard Deviation: 0.87\n",
      "Median: 4.00\n",
      "Min: 1.00\n",
      "Max: 5.00\n",
      "Q1: 3.00\n",
      "Q3: 4.00\n",
      "\n",
      "Justification Explainability Value Distribution:\n",
      "Value 1: 1 occurrences (0.2%)\n",
      "Value 2: 38 occurrences (7.4%)\n",
      "Value 3: 111 occurrences (21.6%)\n",
      "Value 4: 238 occurrences (46.2%)\n",
      "Value 5: 127 occurrences (24.7%)\n",
      "\n",
      "Per-Claim Statistics:\n",
      "\n",
      "Claim 1: 3.94 (95% CI: [3.86, 4.02])\n",
      "\n",
      "Claim 1 Value Distribution:\n",
      "Value 2: 23 occurrences (5.6%)\n",
      "Value 3: 81 occurrences (19.7%)\n",
      "Value 4: 206 occurrences (50.0%)\n",
      "Value 5: 102 occurrences (24.8%)\n",
      "\n",
      "Claim 2: 3.82 (95% CI: [3.74, 3.91])\n",
      "\n",
      "Claim 2 Value Distribution:\n",
      "Value 1: 2 occurrences (0.5%)\n",
      "Value 2: 31 occurrences (7.5%)\n",
      "Value 3: 103 occurrences (25.0%)\n",
      "Value 4: 178 occurrences (43.2%)\n",
      "Value 5: 98 occurrences (23.8%)\n",
      "\n",
      "Claim 3: 3.93 (95% CI: [3.84, 4.02])\n",
      "\n",
      "Claim 3 Value Distribution:\n",
      "Value 1: 2 occurrences (0.5%)\n",
      "Value 2: 32 occurrences (7.8%)\n",
      "Value 3: 80 occurrences (19.4%)\n",
      "Value 4: 177 occurrences (43.0%)\n",
      "Value 5: 121 occurrences (29.4%)\n",
      "\n",
      "Claim 4: 3.70 (95% CI: [3.61, 3.79])\n",
      "\n",
      "Claim 4 Value Distribution:\n",
      "Value 2: 50 occurrences (12.1%)\n",
      "Value 3: 104 occurrences (25.2%)\n",
      "Value 4: 177 occurrences (43.0%)\n",
      "Value 5: 81 occurrences (19.7%)\n",
      "\n",
      "Claim 5: 3.87 (95% CI: [3.78, 3.96])\n",
      "\n",
      "Claim 5 Value Distribution:\n",
      "Value 1: 4 occurrences (1.0%)\n",
      "Value 2: 31 occurrences (7.5%)\n",
      "Value 3: 90 occurrences (21.8%)\n",
      "Value 4: 175 occurrences (42.5%)\n",
      "Value 5: 112 occurrences (27.2%)\n"
     ]
    }
   ],
   "execution_count": 235
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:47.811460Z",
     "start_time": "2025-02-02T23:21:47.795575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# es statistics\n",
    "\n",
    "es_df = pd.read_csv(f\"{output_dir}/processed/es_process_phase_1.csv\")\n",
    "\n",
    "relevance_cols = [col for col in es_df.columns if 'explanations_relevance' in col]\n",
    "effectiveness_cols = [col for col in es_df.columns if 'explanations_effectiveness' in col]\n",
    "logical_cols = [col for col in es_df.columns if 'verdicts_logical_connection' in col]\n",
    "\n",
    "def get_comprehensive_stats(df, cols):\n",
    "   all_values = df[cols].values.ravel()\n",
    "   \n",
    "   mean = np.mean(all_values)\n",
    "   std = np.std(all_values)\n",
    "   n = len(all_values)\n",
    "   se = scipy.stats.sem(all_values)\n",
    "   ci = scipy.stats.t.interval(confidence=0.95, df=n-1, loc=mean, scale=se)\n",
    "   \n",
    "   value_counts = pd.Series(all_values).value_counts().sort_index()\n",
    "   percentages = (value_counts / len(all_values) * 100).round(2)\n",
    "   \n",
    "   return {\n",
    "       'basic_stats': {\n",
    "           'mean': mean,\n",
    "           'std': std,\n",
    "           'median': np.median(all_values),\n",
    "           'min': np.min(all_values),\n",
    "           'max': np.max(all_values),\n",
    "           'q1': np.percentile(all_values, 25),\n",
    "           'q3': np.percentile(all_values, 75),\n",
    "           'ci_lower': ci[0],\n",
    "           'ci_upper': ci[1]\n",
    "       },\n",
    "       'distribution': {\n",
    "           'values': value_counts.index.tolist(),\n",
    "           'counts': value_counts.tolist(),\n",
    "           'percentages': percentages.tolist()\n",
    "       },\n",
    "       'raw_values': all_values\n",
    "   }\n",
    "\n",
    "dimensions = {\n",
    "   'Explanations Relevance': {'cols': relevance_cols, 'stats': None},\n",
    "   'Explanations Effectiveness': {'cols': effectiveness_cols, 'stats': None},\n",
    "   'Verdicts Logical Connection': {'cols': logical_cols, 'stats': None}\n",
    "}\n",
    "\n",
    "for dim_name, dim_data in dimensions.items():\n",
    "   dim_data['stats'] = get_comprehensive_stats(es_df, dim_data['cols'])\n",
    "\n",
    "claim_stats = {}\n",
    "for i in range(1, 6):\n",
    "   claim_cols = [col for col in es_df.columns if f'claim{i}' in col]\n",
    "   claim_stats[f'claim_{i}'] = get_comprehensive_stats(es_df, claim_cols)\n",
    "\n",
    "def print_basic_stats(stats, dimension):\n",
    "   bs = stats['basic_stats']\n",
    "   print(f\"\\n{dimension} Statistics:\")\n",
    "   print(f\"Mean: {bs['mean']:.2f} (95% CI: [{bs['ci_lower']:.2f}, {bs['ci_upper']:.2f}])\")\n",
    "   print(f\"Standard Deviation: {bs['std']:.2f}\")\n",
    "   print(f\"Median: {bs['median']:.2f}\")\n",
    "   print(f\"Min: {bs['min']:.2f}\")\n",
    "   print(f\"Max: {bs['max']:.2f}\")\n",
    "   print(f\"Q1: {bs['q1']:.2f}\")\n",
    "   print(f\"Q3: {bs['q3']:.2f}\")\n",
    "\n",
    "def print_distribution(stats, dimension):\n",
    "   dist = stats['distribution']\n",
    "   print(f\"\\n{dimension} Value Distribution:\")\n",
    "   for val, count, pct in zip(dist['values'], dist['counts'], dist['percentages']):\n",
    "       print(f\"Value {val}: {count} occurrences ({pct:.1f}%)\")\n",
    "\n",
    "for dim_name, dim_data in dimensions.items():\n",
    "   print_basic_stats(dim_data['stats'], dim_name)\n",
    "   print_distribution(dim_data['stats'], dim_name)\n",
    "\n",
    "print(\"\\nPer-Claim Statistics:\")\n",
    "for i in range(1, 6):\n",
    "   stats = claim_stats[f'claim_{i}']\n",
    "   mean = stats['basic_stats']['mean']\n",
    "   ci_lower = stats['basic_stats']['ci_lower']\n",
    "   ci_upper = stats['basic_stats']['ci_upper']\n",
    "   print(f\"\\nClaim {i}: {mean:.2f} (95% CI: [{ci_lower:.2f}, {ci_upper:.2f}])\")\n",
    "   print_distribution(stats, f\"Claim {i}\")\n",
    "\n",
    "stats_data = {\n",
    "   'dimensions': dimensions,\n",
    "   'claims': claim_stats\n",
    "}"
   ],
   "id": "7033e05f30603e91",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Explanations Relevance Statistics:\n",
      "Mean: 3.68 (95% CI: [3.59, 3.76])\n",
      "Standard Deviation: 0.95\n",
      "Median: 4.00\n",
      "Min: 1.00\n",
      "Max: 5.00\n",
      "Q1: 3.00\n",
      "Q3: 4.00\n",
      "\n",
      "Explanations Relevance Value Distribution:\n",
      "Value 1: 7 occurrences (1.4%)\n",
      "Value 2: 56 occurrences (10.9%)\n",
      "Value 3: 133 occurrences (25.8%)\n",
      "Value 4: 220 occurrences (42.7%)\n",
      "Value 5: 99 occurrences (19.2%)\n",
      "\n",
      "Explanations Effectiveness Statistics:\n",
      "Mean: 3.61 (95% CI: [3.52, 3.69])\n",
      "Standard Deviation: 1.00\n",
      "Median: 4.00\n",
      "Min: 1.00\n",
      "Max: 5.00\n",
      "Q1: 3.00\n",
      "Q3: 4.00\n",
      "\n",
      "Explanations Effectiveness Value Distribution:\n",
      "Value 1: 11 occurrences (2.1%)\n",
      "Value 2: 65 occurrences (12.6%)\n",
      "Value 3: 135 occurrences (26.2%)\n",
      "Value 4: 208 occurrences (40.4%)\n",
      "Value 5: 96 occurrences (18.6%)\n",
      "\n",
      "Verdicts Logical Connection Statistics:\n",
      "Mean: 3.67 (95% CI: [3.58, 3.75])\n",
      "Standard Deviation: 0.96\n",
      "Median: 4.00\n",
      "Min: 1.00\n",
      "Max: 5.00\n",
      "Q1: 3.00\n",
      "Q3: 4.00\n",
      "\n",
      "Verdicts Logical Connection Value Distribution:\n",
      "Value 1: 6 occurrences (1.2%)\n",
      "Value 2: 59 occurrences (11.5%)\n",
      "Value 3: 141 occurrences (27.4%)\n",
      "Value 4: 204 occurrences (39.6%)\n",
      "Value 5: 105 occurrences (20.4%)\n",
      "\n",
      "Per-Claim Statistics:\n",
      "\n",
      "Claim 1: 3.74 (95% CI: [3.64, 3.85])\n",
      "\n",
      "Claim 1 Value Distribution:\n",
      "Value 1: 1 occurrences (0.3%)\n",
      "Value 2: 35 occurrences (11.3%)\n",
      "Value 3: 74 occurrences (23.9%)\n",
      "Value 4: 131 occurrences (42.4%)\n",
      "Value 5: 68 occurrences (22.0%)\n",
      "\n",
      "Claim 2: 3.63 (95% CI: [3.51, 3.74])\n",
      "\n",
      "Claim 2 Value Distribution:\n",
      "Value 1: 8 occurrences (2.6%)\n",
      "Value 2: 37 occurrences (12.0%)\n",
      "Value 3: 84 occurrences (27.2%)\n",
      "Value 4: 113 occurrences (36.6%)\n",
      "Value 5: 67 occurrences (21.7%)\n",
      "\n",
      "Claim 3: 3.81 (95% CI: [3.71, 3.91])\n",
      "\n",
      "Claim 3 Value Distribution:\n",
      "Value 2: 30 occurrences (9.7%)\n",
      "Value 3: 70 occurrences (22.6%)\n",
      "Value 4: 138 occurrences (44.7%)\n",
      "Value 5: 71 occurrences (23.0%)\n",
      "\n",
      "Claim 4: 3.35 (95% CI: [3.23, 3.46])\n",
      "\n",
      "Claim 4 Value Distribution:\n",
      "Value 1: 11 occurrences (3.6%)\n",
      "Value 2: 56 occurrences (18.1%)\n",
      "Value 3: 95 occurrences (30.7%)\n",
      "Value 4: 108 occurrences (35.0%)\n",
      "Value 5: 39 occurrences (12.6%)\n",
      "\n",
      "Claim 5: 3.72 (95% CI: [3.62, 3.82])\n",
      "\n",
      "Claim 5 Value Distribution:\n",
      "Value 1: 4 occurrences (1.3%)\n",
      "Value 2: 22 occurrences (7.1%)\n",
      "Value 3: 86 occurrences (27.8%)\n",
      "Value 4: 142 occurrences (46.0%)\n",
      "Value 5: 55 occurrences (17.8%)\n"
     ]
    }
   ],
   "execution_count": 236
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:47.878835Z",
     "start_time": "2025-02-02T23:21:47.856332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# fc statistics\n",
    "\n",
    "fc_df = pd.read_csv(f\"{output_dir}/processed/fc_process_phase_1.csv\")\n",
    "\n",
    "coverage_cols = [col for col in fc_df.columns if 'summary_coverage' in col]\n",
    "support_cols = [col for col in fc_df.columns if 'summary_verdict_support' in col]\n",
    "alignment_cols = [col for col in fc_df.columns if 'summaries_allignment' in col]\n",
    "choice_cols = [col for col in fc_df.columns if 'summary_choice' in col]\n",
    "\n",
    "def get_comprehensive_stats(df, cols, scale_max):\n",
    "    all_values = df[cols].values.ravel()\n",
    "    \n",
    "    mean = np.mean(all_values)\n",
    "    std = np.std(all_values)\n",
    "    n = len(all_values)\n",
    "    se = scipy.stats.sem(all_values)\n",
    "    ci = scipy.stats.t.interval(confidence=0.95, df=n-1, loc=mean, scale=se)\n",
    "    \n",
    "    value_counts = pd.Series(all_values).value_counts().sort_index()\n",
    "    percentages = (value_counts / len(all_values) * 100).round(2)\n",
    "    \n",
    "    return {\n",
    "        'basic_stats': {\n",
    "            'mean': mean,\n",
    "            'std': std,\n",
    "            'median': np.median(all_values),\n",
    "            'min': np.min(all_values),\n",
    "            'max': np.max(all_values),\n",
    "            'q1': np.percentile(all_values, 25),\n",
    "            'q3': np.percentile(all_values, 75),\n",
    "            'ci_lower': ci[0],\n",
    "            'ci_upper': ci[1],\n",
    "            'mean_percentage': (mean/scale_max)*100\n",
    "        },\n",
    "        'distribution': {\n",
    "            'values': value_counts.index.tolist(),\n",
    "            'counts': value_counts.tolist(),\n",
    "            'percentages': percentages.tolist()\n",
    "        },\n",
    "        'raw_values': all_values\n",
    "    }\n",
    "\n",
    "dimensions = {\n",
    "    'Summary Coverage': {'cols': coverage_cols, 'scale_max': 5, 'stats': None},\n",
    "    'Summary Verdict Support': {'cols': support_cols, 'scale_max': 5, 'stats': None},\n",
    "    'Summaries Alignment': {'cols': alignment_cols, 'scale_max': 4, 'stats': None},\n",
    "    'Summary Choice': {'cols': choice_cols, 'scale_max': 5, 'stats': None}\n",
    "}\n",
    "\n",
    "for dim_name, dim_data in dimensions.items():\n",
    "    dim_data['stats'] = get_comprehensive_stats(fc_df, dim_data['cols'], dim_data['scale_max'])\n",
    "\n",
    "def print_basic_stats(stats, dimension, scale_max):\n",
    "    bs = stats['basic_stats']\n",
    "    print(f\"\\n{dimension} Statistics (Scale 1-{scale_max}):\")\n",
    "    print(f\"Mean: {bs['mean']:.2f} (95% CI: [{bs['ci_lower']:.2f}, {bs['ci_upper']:.2f}])\")\n",
    "    print(f\"Standard Deviation: {bs['std']:.2f}\")\n",
    "    print(f\"Median: {bs['median']:.2f}\")\n",
    "    print(f\"Min: {bs['min']:.2f}\")\n",
    "    print(f\"Max: {bs['max']:.2f}\")\n",
    "    print(f\"Q1: {bs['q1']:.2f}\")\n",
    "    print(f\"Q3: {bs['q3']:.2f}\")\n",
    "    print(f\"Mean as % of maximum: {bs['mean_percentage']:.1f}%\")\n",
    "\n",
    "def print_distribution(stats, dimension):\n",
    "    dist = stats['distribution']\n",
    "    print(f\"\\n{dimension} Value Distribution:\")\n",
    "    for val, count, pct in zip(dist['values'], dist['counts'], dist['percentages']):\n",
    "        print(f\"Value {val}: {count} occurrences ({pct:.1f}%)\")\n",
    "\n",
    "for dim_name, dim_data in dimensions.items():\n",
    "    print_basic_stats(dim_data['stats'], dim_name, dim_data['scale_max'])\n",
    "    print_distribution(dim_data['stats'], dim_name)\n",
    "\n",
    "print(\"\\nPer-Claim Analysis (Separated by Scale):\")\n",
    "\n",
    "scale5_dimensions = ['Summary Coverage', 'Summary Verdict Support', 'Summary Choice']\n",
    "print(\"\\nAnalysis for 1-5 scale metrics:\")\n",
    "for i in range(1, 6):\n",
    "    claim_cols = []\n",
    "    for dim in scale5_dimensions:\n",
    "        cols = [col for col in dimensions[dim]['cols'] if f'claim{i}' in col]\n",
    "        claim_cols.extend(cols)\n",
    "    if claim_cols:\n",
    "        stats = get_comprehensive_stats(fc_df, claim_cols, 5)\n",
    "        print(f\"\\nClaim {i} (1-5 scale metrics):\")\n",
    "        print(f\"Mean: {stats['basic_stats']['mean']:.2f} (95% CI: [{stats['basic_stats']['ci_lower']:.2f}, {stats['basic_stats']['ci_upper']:.2f}])\")\n",
    "        print_distribution(stats, f\"Claim {i}\")\n",
    "\n",
    "print(\"\\nAnalysis for 1-4 scale metric (Summaries Alignment):\")\n",
    "for i in range(1, 6):\n",
    "    claim_cols = [col for col in alignment_cols if f'claim{i}' in col]\n",
    "    if claim_cols:\n",
    "        stats = get_comprehensive_stats(fc_df, claim_cols, 4)\n",
    "        print(f\"\\nClaim {i} Alignment:\")\n",
    "        print(f\"Mean: {stats['basic_stats']['mean']:.2f} (95% CI: [{stats['basic_stats']['ci_lower']:.2f}, {stats['basic_stats']['ci_upper']:.2f}])\")\n",
    "        print_distribution(stats, f\"Claim {i}\")"
   ],
   "id": "9526d2e28bee9ac1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Coverage Statistics (Scale 1-5):\n",
      "Mean: 3.60 (95% CI: [3.52, 3.69])\n",
      "Standard Deviation: 0.97\n",
      "Median: 4.00\n",
      "Min: 1.00\n",
      "Max: 5.00\n",
      "Q1: 3.00\n",
      "Q3: 4.00\n",
      "Mean as % of maximum: 72.1%\n",
      "\n",
      "Summary Coverage Value Distribution:\n",
      "Value 1: 3 occurrences (0.6%)\n",
      "Value 2: 71 occurrences (13.8%)\n",
      "Value 3: 152 occurrences (29.5%)\n",
      "Value 4: 190 occurrences (36.9%)\n",
      "Value 5: 99 occurrences (19.2%)\n",
      "\n",
      "Summary Verdict Support Statistics (Scale 1-5):\n",
      "Mean: 3.57 (95% CI: [3.48, 3.65])\n",
      "Standard Deviation: 0.97\n",
      "Median: 4.00\n",
      "Min: 1.00\n",
      "Max: 5.00\n",
      "Q1: 3.00\n",
      "Q3: 4.00\n",
      "Mean as % of maximum: 71.3%\n",
      "\n",
      "Summary Verdict Support Value Distribution:\n",
      "Value 1: 7 occurrences (1.4%)\n",
      "Value 2: 67 occurrences (13.0%)\n",
      "Value 3: 160 occurrences (31.1%)\n",
      "Value 4: 189 occurrences (36.7%)\n",
      "Value 5: 92 occurrences (17.9%)\n",
      "\n",
      "Summaries Alignment Statistics (Scale 1-4):\n",
      "Mean: 2.79 (95% CI: [2.71, 2.87])\n",
      "Standard Deviation: 0.92\n",
      "Median: 3.00\n",
      "Min: 1.00\n",
      "Max: 4.00\n",
      "Q1: 2.00\n",
      "Q3: 3.00\n",
      "Mean as % of maximum: 69.7%\n",
      "\n",
      "Summaries Alignment Value Distribution:\n",
      "Value 1: 58 occurrences (11.3%)\n",
      "Value 2: 112 occurrences (21.8%)\n",
      "Value 3: 227 occurrences (44.1%)\n",
      "Value 4: 118 occurrences (22.9%)\n",
      "\n",
      "Summary Choice Statistics (Scale 1-5):\n",
      "Mean: 3.69 (95% CI: [3.58, 3.79])\n",
      "Standard Deviation: 1.20\n",
      "Median: 4.00\n",
      "Min: 1.00\n",
      "Max: 5.00\n",
      "Q1: 3.00\n",
      "Q3: 5.00\n",
      "Mean as % of maximum: 73.7%\n",
      "\n",
      "Summary Choice Value Distribution:\n",
      "Value 1: 26 occurrences (5.0%)\n",
      "Value 2: 71 occurrences (13.8%)\n",
      "Value 3: 109 occurrences (21.2%)\n",
      "Value 4: 141 occurrences (27.4%)\n",
      "Value 5: 168 occurrences (32.6%)\n",
      "\n",
      "Per-Claim Analysis (Separated by Scale):\n",
      "\n",
      "Analysis for 1-5 scale metrics:\n",
      "\n",
      "Claim 1 (1-5 scale metrics):\n",
      "Mean: 3.76 (95% CI: [3.64, 3.87])\n",
      "\n",
      "Claim 1 Value Distribution:\n",
      "Value 1: 3 occurrences (1.0%)\n",
      "Value 2: 37 occurrences (12.0%)\n",
      "Value 3: 76 occurrences (24.6%)\n",
      "Value 4: 109 occurrences (35.3%)\n",
      "Value 5: 84 occurrences (27.2%)\n",
      "\n",
      "Claim 2 (1-5 scale metrics):\n",
      "Mean: 3.44 (95% CI: [3.33, 3.56])\n",
      "\n",
      "Claim 2 Value Distribution:\n",
      "Value 1: 8 occurrences (2.6%)\n",
      "Value 2: 53 occurrences (17.1%)\n",
      "Value 3: 94 occurrences (30.4%)\n",
      "Value 4: 102 occurrences (33.0%)\n",
      "Value 5: 52 occurrences (16.8%)\n",
      "\n",
      "Claim 3 (1-5 scale metrics):\n",
      "Mean: 3.81 (95% CI: [3.68, 3.93])\n",
      "\n",
      "Claim 3 Value Distribution:\n",
      "Value 1: 13 occurrences (4.2%)\n",
      "Value 2: 23 occurrences (7.4%)\n",
      "Value 3: 80 occurrences (25.9%)\n",
      "Value 4: 87 occurrences (28.2%)\n",
      "Value 5: 106 occurrences (34.3%)\n",
      "\n",
      "Claim 4 (1-5 scale metrics):\n",
      "Mean: 3.43 (95% CI: [3.32, 3.55])\n",
      "\n",
      "Claim 4 Value Distribution:\n",
      "Value 1: 5 occurrences (1.6%)\n",
      "Value 2: 62 occurrences (20.1%)\n",
      "Value 3: 85 occurrences (27.5%)\n",
      "Value 4: 108 occurrences (35.0%)\n",
      "Value 5: 49 occurrences (15.9%)\n",
      "\n",
      "Claim 5 (1-5 scale metrics):\n",
      "Mean: 3.65 (95% CI: [3.54, 3.77])\n",
      "\n",
      "Claim 5 Value Distribution:\n",
      "Value 1: 7 occurrences (2.3%)\n",
      "Value 2: 34 occurrences (11.0%)\n",
      "Value 3: 86 occurrences (27.8%)\n",
      "Value 4: 114 occurrences (36.9%)\n",
      "Value 5: 68 occurrences (22.0%)\n",
      "\n",
      "Analysis for 1-4 scale metric (Summaries Alignment):\n",
      "\n",
      "Claim 1 Alignment:\n",
      "Mean: 2.84 (95% CI: [2.69, 3.00])\n",
      "\n",
      "Claim 1 Value Distribution:\n",
      "Value 1: 7 occurrences (6.8%)\n",
      "Value 2: 22 occurrences (21.4%)\n",
      "Value 3: 54 occurrences (52.4%)\n",
      "Value 4: 20 occurrences (19.4%)\n",
      "\n",
      "Claim 2 Alignment:\n",
      "Mean: 2.54 (95% CI: [2.38, 2.71])\n",
      "\n",
      "Claim 2 Value Distribution:\n",
      "Value 1: 11 occurrences (10.7%)\n",
      "Value 2: 38 occurrences (36.9%)\n",
      "Value 3: 41 occurrences (39.8%)\n",
      "Value 4: 13 occurrences (12.6%)\n",
      "\n",
      "Claim 3 Alignment:\n",
      "Mean: 3.19 (95% CI: [3.02, 3.37])\n",
      "\n",
      "Claim 3 Value Distribution:\n",
      "Value 1: 8 occurrences (7.8%)\n",
      "Value 2: 9 occurrences (8.7%)\n",
      "Value 3: 41 occurrences (39.8%)\n",
      "Value 4: 45 occurrences (43.7%)\n",
      "\n",
      "Claim 4 Alignment:\n",
      "Mean: 2.65 (95% CI: [2.45, 2.85])\n",
      "\n",
      "Claim 4 Value Distribution:\n",
      "Value 1: 19 occurrences (18.4%)\n",
      "Value 2: 20 occurrences (19.4%)\n",
      "Value 3: 42 occurrences (40.8%)\n",
      "Value 4: 22 occurrences (21.4%)\n",
      "\n",
      "Claim 5 Alignment:\n",
      "Mean: 2.70 (95% CI: [2.52, 2.88])\n",
      "\n",
      "Claim 5 Value Distribution:\n",
      "Value 1: 13 occurrences (12.6%)\n",
      "Value 2: 23 occurrences (22.3%)\n",
      "Value 3: 49 occurrences (47.6%)\n",
      "Value 4: 18 occurrences (17.5%)\n"
     ]
    }
   ],
   "execution_count": 237
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:47.981745Z",
     "start_time": "2025-02-02T23:21:47.973389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# processing participants data\n",
    "\n",
    "df = pd.read_csv(f\"{output_dir}/participants_data.csv\")\n",
    "participants_processed = df.copy()\n",
    "\n",
    "participants_processed = participants_processed.drop('email', axis=1)\n",
    "\n",
    "participants_processed['english_level'] = participants_processed['english_level'].str.extract(r'\\((.*?)\\)', expand=False)\n",
    "participants_processed['political_orientation'] = participants_processed['political_orientation'].str.extract(r'\\((.*?)\\)', expand=False)\n",
    "\n",
    "output_path = os.path.join(processed_dir, 'participants_data_phase_1.csv')\n",
    "participants_processed.to_csv(output_path, index=False)"
   ],
   "id": "510e7788b9a07f62",
   "outputs": [],
   "execution_count": 238
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:48.003751Z",
     "start_time": "2025-02-02T23:21:47.996283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# demographics data information\n",
    "\n",
    "participants = pd.read_csv(f\"{output_dir}/processed/participants_data_phase_1.csv\")\n",
    "\n",
    "print(\"Demographics Distribution:\\n\")\n",
    "print(\"Age Groups:\")\n",
    "print(participants['age_group'].value_counts(normalize=True) * 100)\n",
    "print(\"\\nEducation Levels:\")\n",
    "print(participants['education_level'].value_counts(normalize=True) * 100)\n",
    "print(\"\\nEnglish Proficiency:\")\n",
    "print(participants['english_level'].value_counts(normalize=True) * 100)\n",
    "print(\"\\nPolitical Orientation:\")\n",
    "print(participants['political_orientation'].value_counts(normalize=True) * 100)\n",
    "print(\"\\nFact-checking Experience (years):\")\n",
    "print(participants['fc_years_of_experience'].value_counts(normalize=True) * 100)"
   ],
   "id": "eaa2d368a4abd27f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographics Distribution:\n",
      "\n",
      "Age Groups:\n",
      "age_group\n",
      "26-35 years old      36.893204\n",
      "18-25 years old      29.126214\n",
      "36-50 years old      26.213592\n",
      "Over 50 years old     7.766990\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Education Levels:\n",
      "education_level\n",
      "Bachelor's degree                    52.427184\n",
      "Master's degree                      34.951456\n",
      "High school diploma or equivalent     7.766990\n",
      "Doctoral degree (PhD)                 2.912621\n",
      "I prefer not to answer                1.941748\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "English Proficiency:\n",
      "english_level\n",
      "Native speaker          64.705882\n",
      "High proficiency        25.490196\n",
      "Moderate proficiency     8.823529\n",
      "Basic comprehension      0.980392\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Political Orientation:\n",
      "political_orientation\n",
      "Very Liberal               37.373737\n",
      "Moderately Liberal         32.323232\n",
      "Moderate                   21.212121\n",
      "Moderately Conservative     8.080808\n",
      "Very Conservative           1.010101\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Fact-checking Experience (years):\n",
      "fc_years_of_experience\n",
      "2-5 years                                38.834951\n",
      "More than 10 years                       24.271845\n",
      "Less than 2 years                        16.504854\n",
      "5-10 years                               13.592233\n",
      "No dedicated fact-checking experience     6.796117\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 239
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:48.390122Z",
     "start_time": "2025-02-02T23:21:48.049213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# processed averages per participant\n",
    "\n",
    "cd_df = pd.read_csv(f\"{output_dir}/processed/cd_process_phase_1.csv\")\n",
    "es_df = pd.read_csv(f\"{output_dir}/processed/es_process_phase_1.csv\")\n",
    "fc_df = pd.read_csv(f\"{output_dir}/processed/fc_process_phase_1.csv\")\n",
    "proc_df = pd.read_csv(f\"{output_dir}/processed/process_evaluation_phase_1.csv\")\n",
    "participants_df = pd.read_csv(f\"{output_dir}/processed/participants_data_phase_1.csv\")\n",
    "\n",
    "participant_averages = {}\n",
    "participant_ids = cd_df['prolific_id'].unique()\n",
    "\n",
    "for pid in participant_ids:\n",
    "    participant_averages[pid] = {}\n",
    "    \n",
    "    cd_participant = cd_df[cd_df['prolific_id'] == pid]\n",
    "    participant_averages[pid].update({\n",
    "        'cd_overall': cd_participant.iloc[:, 1:].mean().mean(),  # Skip prolific_id column\n",
    "        'cd_coverage': cd_participant[[col for col in cd_participant.columns if 'coverage' in col]].mean().mean(),\n",
    "        'cd_relevance': cd_participant[[col for col in cd_participant.columns if 'relevance' in col]].mean().mean(),\n",
    "        'cd_formulation': cd_participant[[col for col in cd_participant.columns if 'formulation' in col]].mean().mean(),\n",
    "        'cd_explainability': cd_participant[[col for col in cd_participant.columns if 'explainability' in col]].mean().mean()\n",
    "    })\n",
    "    \n",
    "    # ES averages\n",
    "    es_participant = es_df[es_df['prolific_id'] == pid]\n",
    "    participant_averages[pid].update({\n",
    "        'es_overall': es_participant.iloc[:, 1:].mean().mean(),  # Skip prolific_id column\n",
    "        'es_relevance': es_participant[[col for col in es_participant.columns if 'relevance' in col]].mean().mean(),\n",
    "        'es_effectiveness': es_participant[[col for col in es_participant.columns if 'effectiveness' in col]].mean().mean(),\n",
    "        'es_logical_connection': es_participant[[col for col in es_participant.columns if 'logical_connection' in col]].mean().mean()\n",
    "    })\n",
    "    \n",
    "    fc_participant = fc_df[fc_df['prolific_id'] == pid]\n",
    "    scale5_cols = ([col for col in fc_participant.columns if 'coverage' in col] + \n",
    "                   [col for col in fc_participant.columns if 'support' in col] + \n",
    "                   [col for col in fc_participant.columns if 'choice' in col])\n",
    "    participant_averages[pid].update({\n",
    "        'fc_scale5_overall': fc_participant[scale5_cols].mean().mean(),\n",
    "        'fc_coverage': fc_participant[[col for col in fc_participant.columns if 'coverage' in col]].mean().mean(),\n",
    "        'fc_support': fc_participant[[col for col in fc_participant.columns if 'support' in col]].mean().mean(),\n",
    "        'fc_choice': fc_participant[[col for col in fc_participant.columns if 'choice' in col]].mean().mean(),\n",
    "        'fc_alignment': fc_participant[[col for col in fc_participant.columns if 'allignment' in col]].mean().mean()\n",
    "    })\n",
    "    \n",
    "    proc_participant = proc_df[proc_df['prolific_id'] == pid]\n",
    "    scale5_cols = ['process_explainability', 'process_transparency', 'sources_transparency', 'process_level_of_trust']\n",
    "    participant_averages[pid].update({\n",
    "        'proc_scale5_overall': proc_participant[scale5_cols].mean().mean(),\n",
    "        'proc_explainability': proc_participant['process_explainability'].values[0],\n",
    "        'proc_transparency': proc_participant['process_transparency'].values[0],\n",
    "        'proc_sources_transparency': proc_participant['sources_transparency'].values[0],\n",
    "        'proc_trust': proc_participant['process_level_of_trust'].values[0],\n",
    "        'proc_credibility': proc_participant['process_credibility'].values[0]\n",
    "    })\n",
    "    \n",
    "    participant_demo = participants_df[participants_df['prolific_id'] == pid]\n",
    "    participant_averages[pid].update({\n",
    "        'age_group': participant_demo['age_group'].values[0],\n",
    "        'english_level': participant_demo['english_level'].values[0],\n",
    "        'education_level': participant_demo['education_level'].values[0],\n",
    "        'political_orientation': participant_demo['political_orientation'].values[0],\n",
    "        'fc_years_of_experience': participant_demo['fc_years_of_experience'].values[0]\n",
    "    })\n",
    "\n",
    "participant_averages_df = pd.DataFrame.from_dict(participant_averages, orient='index')\n",
    "participant_averages_df.index.name = 'prolific_id'\n",
    "output_path = f\"{output_dir}/processed/participants_averages_phase_1.csv\"\n",
    "participant_averages_df.to_csv(output_path)"
   ],
   "id": "623d65a3711be69e",
   "outputs": [],
   "execution_count": 240
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:48.550152Z",
     "start_time": "2025-02-02T23:21:48.431902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "df = pd.read_csv(f\"{output_dir}/processed/participants_averages_phase_1.csv\")\n",
    "\n",
    "evaluation_metrics = {\n",
    "    'Claim Decomposition': ['cd_overall', 'cd_coverage', 'cd_relevance', 'cd_formulation', 'cd_explainability'],\n",
    "    'Evidence Synthesis': ['es_overall', 'es_relevance', 'es_effectiveness', 'es_logical_connection'],\n",
    "    'Final Conclusion': ['fc_scale5_overall', 'fc_coverage', 'fc_support', 'fc_choice', 'fc_alignment'],\n",
    "    'Process Evaluation': ['proc_scale5_overall', 'proc_explainability', 'proc_transparency', \n",
    "                          'proc_sources_transparency', 'proc_trust']\n",
    "}\n",
    "\n",
    "def run_statistical_tests(group_column, value_columns, df):\n",
    "    results = []\n",
    "    \n",
    "    for col in value_columns:\n",
    "        valid_data = df[[group_column, col]].dropna()\n",
    "        \n",
    "        if len(valid_data) > 0:\n",
    "            # Kruskal-Wallis H-test\n",
    "            groups = [group for _, group in valid_data.groupby(group_column)[col]]\n",
    "            h_stat, p_value = stats.kruskal(*groups)\n",
    "            \n",
    "            # Get mean values and counts for each group\n",
    "            group_stats = valid_data.groupby(group_column)[col].agg(['mean', 'count'])\n",
    "            \n",
    "            results.append({\n",
    "                'Metric': col,\n",
    "                'H-statistic': h_stat,\n",
    "                'p-value': p_value,\n",
    "                'Group_Stats': group_stats\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def analyze_demographic(demographic_col, df, metrics_dict):\n",
    "    print(f\"\\nAnalysis for {demographic_col}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Print distribution of demographic groups\n",
    "    print(\"\\nGroup Distribution:\")\n",
    "    group_dist = df[demographic_col].value_counts()\n",
    "    for group, count in group_dist.items():\n",
    "        print(f\"{group}: {count} participants ({count/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    for metric_group, metrics in metrics_dict.items():\n",
    "        results = run_statistical_tests(demographic_col, metrics, df)\n",
    "        \n",
    "        # Print significant results (p < 0.05)\n",
    "        sig_results = results[results['p-value'] < 0.05]\n",
    "        if not sig_results.empty:\n",
    "            print(f\"\\n{metric_group} Metrics:\")\n",
    "            print(\"\\nSignificant differences found:\")\n",
    "            for _, row in sig_results.iterrows():\n",
    "                print(f\"\\n{row['Metric']}:\")\n",
    "                print(f\"H-statistic: {row['H-statistic']:.2f}\")\n",
    "                print(f\"p-value: {row['p-value']:.4f}\")\n",
    "                \n",
    "                # Print group statistics\n",
    "                stats_df = row['Group_Stats']\n",
    "                print(\"\\nGroup statistics:\")\n",
    "                for group in stats_df.index:\n",
    "                    mean = stats_df.loc[group, 'mean']\n",
    "                    count = stats_df.loc[group, 'count']\n",
    "                    print(f\"  {group}: {mean:.2f} (n={count})\")\n",
    "                \n",
    "                # Only make comparisons for groups with sufficient sample size (e.g., n > 5)\n",
    "                valid_groups = stats_df[stats_df['count'] > 5]\n",
    "                if len(valid_groups) >= 2:\n",
    "                    print(\"\\nComparison between groups with sufficient sample size:\")\n",
    "                    print(f\"Range of scores: {valid_groups['mean'].min():.2f} to {valid_groups['mean'].max():.2f}\")\n",
    "                    \n",
    "        else:\n",
    "            print(f\"\\n{metric_group} Metrics:\")\n",
    "            print(\"No significant differences found between groups\")\n",
    "\n",
    "# Run analysis for each demographic factor including fc_years_of_experience\n",
    "demographics = ['age_group', 'education_level', 'english_level', \n",
    "                'political_orientation', 'fc_years_of_experience']\n",
    "for demo in demographics:\n",
    "    analyze_demographic(demo, df, evaluation_metrics)"
   ],
   "id": "83e8c1ca7c1a5543",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis for age_group:\n",
      "--------------------------------------------------\n",
      "\n",
      "Group Distribution:\n",
      "26-35 years old: 38 participants (36.9%)\n",
      "18-25 years old: 30 participants (29.1%)\n",
      "36-50 years old: 27 participants (26.2%)\n",
      "Over 50 years old: 8 participants (7.8%)\n",
      "\n",
      "Claim Decomposition Metrics:\n",
      "\n",
      "Significant differences found:\n",
      "\n",
      "cd_formulation:\n",
      "H-statistic: 8.07\n",
      "p-value: 0.0446\n",
      "\n",
      "Group statistics:\n",
      "  18-25 years old: 3.75 (n=30)\n",
      "  26-35 years old: 3.59 (n=38)\n",
      "  36-50 years old: 3.98 (n=27)\n",
      "  Over 50 years old: 3.92 (n=8)\n",
      "\n",
      "Comparison between groups with sufficient sample size:\n",
      "Range of scores: 3.59 to 3.98\n",
      "\n",
      "Evidence Synthesis Metrics:\n",
      "No significant differences found between groups\n",
      "\n",
      "Final Conclusion Metrics:\n",
      "No significant differences found between groups\n",
      "\n",
      "Process Evaluation Metrics:\n",
      "No significant differences found between groups\n",
      "\n",
      "Analysis for education_level:\n",
      "--------------------------------------------------\n",
      "\n",
      "Group Distribution:\n",
      "Bachelor's degree: 54 participants (52.4%)\n",
      "Master's degree: 36 participants (35.0%)\n",
      "High school diploma or equivalent: 8 participants (7.8%)\n",
      "Doctoral degree (PhD): 3 participants (2.9%)\n",
      "I prefer not to answer: 2 participants (1.9%)\n",
      "\n",
      "Claim Decomposition Metrics:\n",
      "No significant differences found between groups\n",
      "\n",
      "Evidence Synthesis Metrics:\n",
      "\n",
      "Significant differences found:\n",
      "\n",
      "es_overall:\n",
      "H-statistic: 11.52\n",
      "p-value: 0.0213\n",
      "\n",
      "Group statistics:\n",
      "  Bachelor's degree: 3.47 (n=54)\n",
      "  Doctoral degree (PhD): 4.13 (n=3)\n",
      "  High school diploma or equivalent: 3.94 (n=8)\n",
      "  I prefer not to answer: 3.30 (n=2)\n",
      "  Master's degree: 3.84 (n=36)\n",
      "\n",
      "Comparison between groups with sufficient sample size:\n",
      "Range of scores: 3.47 to 3.94\n",
      "\n",
      "es_relevance:\n",
      "H-statistic: 10.51\n",
      "p-value: 0.0327\n",
      "\n",
      "Group statistics:\n",
      "  Bachelor's degree: 3.49 (n=54)\n",
      "  Doctoral degree (PhD): 4.27 (n=3)\n",
      "  High school diploma or equivalent: 4.00 (n=8)\n",
      "  I prefer not to answer: 3.50 (n=2)\n",
      "  Master's degree: 3.84 (n=36)\n",
      "\n",
      "Comparison between groups with sufficient sample size:\n",
      "Range of scores: 3.49 to 4.00\n",
      "\n",
      "es_logical_connection:\n",
      "H-statistic: 13.71\n",
      "p-value: 0.0083\n",
      "\n",
      "Group statistics:\n",
      "  Bachelor's degree: 3.46 (n=54)\n",
      "  Doctoral degree (PhD): 4.20 (n=3)\n",
      "  High school diploma or equivalent: 4.03 (n=8)\n",
      "  I prefer not to answer: 3.10 (n=2)\n",
      "  Master's degree: 3.88 (n=36)\n",
      "\n",
      "Comparison between groups with sufficient sample size:\n",
      "Range of scores: 3.46 to 4.03\n",
      "\n",
      "Final Conclusion Metrics:\n",
      "No significant differences found between groups\n",
      "\n",
      "Process Evaluation Metrics:\n",
      "No significant differences found between groups\n",
      "\n",
      "Analysis for english_level:\n",
      "--------------------------------------------------\n",
      "\n",
      "Group Distribution:\n",
      "Native speaker: 66 participants (64.1%)\n",
      "High proficiency: 26 participants (25.2%)\n",
      "Moderate proficiency: 9 participants (8.7%)\n",
      "Basic comprehension: 1 participants (1.0%)\n",
      "\n",
      "Claim Decomposition Metrics:\n",
      "No significant differences found between groups\n",
      "\n",
      "Evidence Synthesis Metrics:\n",
      "No significant differences found between groups\n",
      "\n",
      "Final Conclusion Metrics:\n",
      "No significant differences found between groups\n",
      "\n",
      "Process Evaluation Metrics:\n",
      "\n",
      "Significant differences found:\n",
      "\n",
      "proc_transparency:\n",
      "H-statistic: 10.45\n",
      "p-value: 0.0151\n",
      "\n",
      "Group statistics:\n",
      "  Basic comprehension: 2.00 (n=1)\n",
      "  High proficiency: 3.31 (n=26)\n",
      "  Moderate proficiency: 3.22 (n=9)\n",
      "  Native speaker: 3.71 (n=66)\n",
      "\n",
      "Comparison between groups with sufficient sample size:\n",
      "Range of scores: 3.22 to 3.71\n",
      "\n",
      "Analysis for political_orientation:\n",
      "--------------------------------------------------\n",
      "\n",
      "Group Distribution:\n",
      "Very Liberal: 37 participants (35.9%)\n",
      "Moderately Liberal: 32 participants (31.1%)\n",
      "Moderate: 21 participants (20.4%)\n",
      "Moderately Conservative: 8 participants (7.8%)\n",
      "Very Conservative: 1 participants (1.0%)\n",
      "\n",
      "Claim Decomposition Metrics:\n",
      "No significant differences found between groups\n",
      "\n",
      "Evidence Synthesis Metrics:\n",
      "No significant differences found between groups\n",
      "\n",
      "Final Conclusion Metrics:\n",
      "\n",
      "Significant differences found:\n",
      "\n",
      "fc_support:\n",
      "H-statistic: 15.46\n",
      "p-value: 0.0038\n",
      "\n",
      "Group statistics:\n",
      "  Moderate: 3.48 (n=21)\n",
      "  Moderately Conservative: 3.20 (n=8)\n",
      "  Moderately Liberal: 3.48 (n=32)\n",
      "  Very Conservative: 4.40 (n=1)\n",
      "  Very Liberal: 3.79 (n=37)\n",
      "\n",
      "Comparison between groups with sufficient sample size:\n",
      "Range of scores: 3.20 to 3.79\n",
      "\n",
      "Process Evaluation Metrics:\n",
      "No significant differences found between groups\n",
      "\n",
      "Analysis for fc_years_of_experience:\n",
      "--------------------------------------------------\n",
      "\n",
      "Group Distribution:\n",
      "2-5 years: 40 participants (38.8%)\n",
      "More than 10 years: 25 participants (24.3%)\n",
      "Less than 2 years: 17 participants (16.5%)\n",
      "5-10 years: 14 participants (13.6%)\n",
      "No dedicated fact-checking experience: 7 participants (6.8%)\n",
      "\n",
      "Claim Decomposition Metrics:\n",
      "No significant differences found between groups\n",
      "\n",
      "Evidence Synthesis Metrics:\n",
      "No significant differences found between groups\n",
      "\n",
      "Final Conclusion Metrics:\n",
      "No significant differences found between groups\n",
      "\n",
      "Process Evaluation Metrics:\n",
      "No significant differences found between groups\n"
     ]
    }
   ],
   "execution_count": 241
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T17:26:48.285316Z",
     "start_time": "2025-02-03T17:26:47.289832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "metrics = {\n",
    "    'Claim Decomposition': [\n",
    "        'cd_overall', 'cd_coverage', 'cd_relevance', 'cd_formulation', 'cd_explainability'\n",
    "    ],\n",
    "    'Evidence Synthesis': [\n",
    "        'es_overall', 'es_relevance', 'es_effectiveness', 'es_logical_connection'\n",
    "    ],\n",
    "    'Final Conclusion': [\n",
    "        'fc_scale5_overall', 'fc_coverage', 'fc_support', 'fc_choice'  # Removed fc_alignment\n",
    "    ],\n",
    "    'Process Evaluation': [\n",
    "        'proc_scale5_overall', 'proc_explainability', 'proc_transparency', \n",
    "        'proc_sources_transparency', 'proc_trust'\n",
    "    ]\n",
    "}\n",
    "\n",
    "def analyze_correlations(df, output_dir):\n",
    "    # Create list of all metrics\n",
    "    all_metrics = []\n",
    "    for phase_metrics in metrics.values():\n",
    "        all_metrics.extend(phase_metrics)\n",
    "\n",
    "    # Calculate correlations\n",
    "    correlations = df[all_metrics].corr()\n",
    "    p_values = pd.DataFrame(np.zeros_like(correlations), columns=correlations.columns, index=correlations.index)\n",
    "\n",
    "    # Calculate p-values\n",
    "    for i in range(len(correlations.columns)):\n",
    "        for j in range(len(correlations.columns)):\n",
    "            coef, p = stats.spearmanr(df[correlations.columns[i]], df[correlations.columns[j]], nan_policy='omit')\n",
    "            p_values.iloc[i,j] = p\n",
    "\n",
    "    # Create and save correlation heatmap\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    sns.heatmap(correlations, annot=True, cmap='RdBu', center=0, fmt='.2f')\n",
    "    plt.title('Correlation Heatmap of All Metrics (Excluding 4-point Scale Items)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/processed/correlation_heatmap_no_4point.png\")\n",
    "    plt.close()\n",
    "\n",
    "    # Save significant correlations to CSV\n",
    "    significant_correlations = []\n",
    "    for i in range(len(correlations.columns)):\n",
    "        for j in range(i + 1, len(correlations.columns)):  # Only upper triangle to avoid duplicates\n",
    "            metric1 = correlations.columns[i]\n",
    "            metric2 = correlations.columns[j]\n",
    "            corr = correlations.iloc[i,j]\n",
    "            p_val = p_values.iloc[i,j]\n",
    "            \n",
    "            if p_val < 0.05:  # Significant correlation\n",
    "                significant_correlations.append({\n",
    "                    'Metric1': metric1,\n",
    "                    'Metric2': metric2,\n",
    "                    'Correlation': corr,\n",
    "                    'P-value': p_val,\n",
    "                    'Strength': 'Strong' if abs(corr) >= 0.5 else 'Moderate' if abs(corr) >= 0.3 else 'Weak',\n",
    "                    'Direction': 'Positive' if corr > 0 else 'Negative'\n",
    "                })\n",
    "\n",
    "    # Save to CSV\n",
    "    pd.DataFrame(significant_correlations).to_csv(\n",
    "        f\"{output_dir}/processed/significant_correlations_no_4point.csv\", \n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    return correlations, p_values\n",
    "\n",
    "# Function to print significant correlations between phases\n",
    "def print_phase_correlations(correlations, p_values, phase1, phase2):\n",
    "    print(f\"\\nSignificant correlations between {phase1} and {phase2}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    metrics1 = metrics[phase1]\n",
    "    metrics2 = metrics[phase2]\n",
    "    \n",
    "    found_significant = False\n",
    "    \n",
    "    for m1 in metrics1:\n",
    "        for m2 in metrics2:\n",
    "            if m1 != m2:  # Don't report correlation with itself\n",
    "                corr = correlations.loc[m1, m2]\n",
    "                p_val = p_values.loc[m1, m2]\n",
    "                \n",
    "                if p_val < 0.05:  # Significant correlation\n",
    "                    found_significant = True\n",
    "                    print(f\"\\n{m1} vs {m2}:\")\n",
    "                    print(f\"Correlation coefficient: {corr:.2f}\")\n",
    "                    print(f\"P-value: {p_val:.4f}\")\n",
    "                    print(\"Interpretation:\", end=\" \")\n",
    "                    if corr > 0:\n",
    "                        print(f\"Positive correlation - as {m1} increases, {m2} tends to increase\")\n",
    "                    else:\n",
    "                        print(f\"Negative correlation - as {m1} increases, {m2} tends to decrease\")\n",
    "                    \n",
    "                    # Add strength interpretation\n",
    "                    abs_corr = abs(corr)\n",
    "                    if abs_corr < 0.3:\n",
    "                        print(\"Strength: Weak correlation\")\n",
    "                    elif abs_corr < 0.5:\n",
    "                        print(\"Strength: Moderate correlation\")\n",
    "                    else:\n",
    "                        print(\"Strength: Strong correlation\")\n",
    "    \n",
    "    if not found_significant:\n",
    "        print(\"No significant correlations found\")\n",
    "\n",
    "# Read the data\n",
    "df = pd.read_csv(f\"{output_dir}/processed/participants_averages_phase_1.csv\")\n",
    "\n",
    "# Run the analysis\n",
    "correlations, p_values = analyze_correlations(df, output_dir)\n",
    "\n",
    "# Print correlations between all pairs of phases\n",
    "phases = list(metrics.keys())\n",
    "for i in range(len(phases)):\n",
    "    for j in range(i + 1, len(phases)):\n",
    "        print_phase_correlations(correlations, p_values, phases[i], phases[j])"
   ],
   "id": "cbc25a11f7d14392",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Significant correlations between Claim Decomposition and Evidence Synthesis:\n",
      "--------------------------------------------------\n",
      "\n",
      "cd_overall vs es_overall:\n",
      "Correlation coefficient: 0.73\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_overall increases, es_overall tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_overall vs es_relevance:\n",
      "Correlation coefficient: 0.71\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_overall increases, es_relevance tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_overall vs es_effectiveness:\n",
      "Correlation coefficient: 0.65\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_overall increases, es_effectiveness tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_overall vs es_logical_connection:\n",
      "Correlation coefficient: 0.70\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_overall increases, es_logical_connection tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_coverage vs es_overall:\n",
      "Correlation coefficient: 0.64\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_coverage increases, es_overall tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_coverage vs es_relevance:\n",
      "Correlation coefficient: 0.66\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_coverage increases, es_relevance tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_coverage vs es_effectiveness:\n",
      "Correlation coefficient: 0.57\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_coverage increases, es_effectiveness tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_coverage vs es_logical_connection:\n",
      "Correlation coefficient: 0.58\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_coverage increases, es_logical_connection tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_relevance vs es_overall:\n",
      "Correlation coefficient: 0.68\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_relevance increases, es_overall tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_relevance vs es_relevance:\n",
      "Correlation coefficient: 0.64\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_relevance increases, es_relevance tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_relevance vs es_effectiveness:\n",
      "Correlation coefficient: 0.64\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_relevance increases, es_effectiveness tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_relevance vs es_logical_connection:\n",
      "Correlation coefficient: 0.65\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_relevance increases, es_logical_connection tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_formulation vs es_overall:\n",
      "Correlation coefficient: 0.64\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_formulation increases, es_overall tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_formulation vs es_relevance:\n",
      "Correlation coefficient: 0.62\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_formulation increases, es_relevance tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_formulation vs es_effectiveness:\n",
      "Correlation coefficient: 0.56\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_formulation increases, es_effectiveness tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_formulation vs es_logical_connection:\n",
      "Correlation coefficient: 0.62\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_formulation increases, es_logical_connection tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_explainability vs es_overall:\n",
      "Correlation coefficient: 0.70\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_explainability increases, es_overall tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_explainability vs es_relevance:\n",
      "Correlation coefficient: 0.67\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_explainability increases, es_relevance tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_explainability vs es_effectiveness:\n",
      "Correlation coefficient: 0.61\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_explainability increases, es_effectiveness tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_explainability vs es_logical_connection:\n",
      "Correlation coefficient: 0.70\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_explainability increases, es_logical_connection tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "Significant correlations between Claim Decomposition and Final Conclusion:\n",
      "--------------------------------------------------\n",
      "\n",
      "cd_overall vs fc_scale5_overall:\n",
      "Correlation coefficient: 0.51\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_overall increases, fc_scale5_overall tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_overall vs fc_coverage:\n",
      "Correlation coefficient: 0.54\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_overall increases, fc_coverage tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_overall vs fc_support:\n",
      "Correlation coefficient: 0.51\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_overall increases, fc_support tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_coverage vs fc_scale5_overall:\n",
      "Correlation coefficient: 0.50\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_coverage increases, fc_scale5_overall tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_coverage vs fc_coverage:\n",
      "Correlation coefficient: 0.51\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_coverage increases, fc_coverage tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_coverage vs fc_support:\n",
      "Correlation coefficient: 0.45\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_coverage increases, fc_support tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "cd_relevance vs fc_scale5_overall:\n",
      "Correlation coefficient: 0.52\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_relevance increases, fc_scale5_overall tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_relevance vs fc_coverage:\n",
      "Correlation coefficient: 0.55\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_relevance increases, fc_coverage tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_relevance vs fc_support:\n",
      "Correlation coefficient: 0.53\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_relevance increases, fc_support tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_formulation vs fc_scale5_overall:\n",
      "Correlation coefficient: 0.33\n",
      "P-value: 0.0008\n",
      "Interpretation: Positive correlation - as cd_formulation increases, fc_scale5_overall tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "cd_formulation vs fc_coverage:\n",
      "Correlation coefficient: 0.38\n",
      "P-value: 0.0003\n",
      "Interpretation: Positive correlation - as cd_formulation increases, fc_coverage tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "cd_formulation vs fc_support:\n",
      "Correlation coefficient: 0.31\n",
      "P-value: 0.0019\n",
      "Interpretation: Positive correlation - as cd_formulation increases, fc_support tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "cd_explainability vs fc_scale5_overall:\n",
      "Correlation coefficient: 0.51\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_explainability increases, fc_scale5_overall tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_explainability vs fc_coverage:\n",
      "Correlation coefficient: 0.54\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_explainability increases, fc_coverage tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "cd_explainability vs fc_support:\n",
      "Correlation coefficient: 0.55\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_explainability increases, fc_support tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "Significant correlations between Claim Decomposition and Process Evaluation:\n",
      "--------------------------------------------------\n",
      "\n",
      "cd_overall vs proc_scale5_overall:\n",
      "Correlation coefficient: 0.38\n",
      "P-value: 0.0010\n",
      "Interpretation: Positive correlation - as cd_overall increases, proc_scale5_overall tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "cd_overall vs proc_explainability:\n",
      "Correlation coefficient: 0.38\n",
      "P-value: 0.0007\n",
      "Interpretation: Positive correlation - as cd_overall increases, proc_explainability tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "cd_overall vs proc_transparency:\n",
      "Correlation coefficient: 0.46\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as cd_overall increases, proc_transparency tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "cd_coverage vs proc_scale5_overall:\n",
      "Correlation coefficient: 0.35\n",
      "P-value: 0.0035\n",
      "Interpretation: Positive correlation - as cd_coverage increases, proc_scale5_overall tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "cd_coverage vs proc_explainability:\n",
      "Correlation coefficient: 0.36\n",
      "P-value: 0.0012\n",
      "Interpretation: Positive correlation - as cd_coverage increases, proc_explainability tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "cd_coverage vs proc_transparency:\n",
      "Correlation coefficient: 0.47\n",
      "P-value: 0.0001\n",
      "Interpretation: Positive correlation - as cd_coverage increases, proc_transparency tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "cd_relevance vs proc_scale5_overall:\n",
      "Correlation coefficient: 0.38\n",
      "P-value: 0.0019\n",
      "Interpretation: Positive correlation - as cd_relevance increases, proc_scale5_overall tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "cd_relevance vs proc_explainability:\n",
      "Correlation coefficient: 0.34\n",
      "P-value: 0.0022\n",
      "Interpretation: Positive correlation - as cd_relevance increases, proc_explainability tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "cd_relevance vs proc_transparency:\n",
      "Correlation coefficient: 0.40\n",
      "P-value: 0.0002\n",
      "Interpretation: Positive correlation - as cd_relevance increases, proc_transparency tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "cd_formulation vs proc_scale5_overall:\n",
      "Correlation coefficient: 0.33\n",
      "P-value: 0.0024\n",
      "Interpretation: Positive correlation - as cd_formulation increases, proc_scale5_overall tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "cd_formulation vs proc_explainability:\n",
      "Correlation coefficient: 0.36\n",
      "P-value: 0.0007\n",
      "Interpretation: Positive correlation - as cd_formulation increases, proc_explainability tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "cd_formulation vs proc_transparency:\n",
      "Correlation coefficient: 0.44\n",
      "P-value: 0.0001\n",
      "Interpretation: Positive correlation - as cd_formulation increases, proc_transparency tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "cd_explainability vs proc_scale5_overall:\n",
      "Correlation coefficient: 0.34\n",
      "P-value: 0.0024\n",
      "Interpretation: Positive correlation - as cd_explainability increases, proc_scale5_overall tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "cd_explainability vs proc_explainability:\n",
      "Correlation coefficient: 0.33\n",
      "P-value: 0.0016\n",
      "Interpretation: Positive correlation - as cd_explainability increases, proc_explainability tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "cd_explainability vs proc_transparency:\n",
      "Correlation coefficient: 0.38\n",
      "P-value: 0.0003\n",
      "Interpretation: Positive correlation - as cd_explainability increases, proc_transparency tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "Significant correlations between Evidence Synthesis and Final Conclusion:\n",
      "--------------------------------------------------\n",
      "\n",
      "es_overall vs fc_scale5_overall:\n",
      "Correlation coefficient: 0.51\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as es_overall increases, fc_scale5_overall tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "es_overall vs fc_coverage:\n",
      "Correlation coefficient: 0.54\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as es_overall increases, fc_coverage tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "es_overall vs fc_support:\n",
      "Correlation coefficient: 0.58\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as es_overall increases, fc_support tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "es_relevance vs fc_scale5_overall:\n",
      "Correlation coefficient: 0.51\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as es_relevance increases, fc_scale5_overall tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "es_relevance vs fc_coverage:\n",
      "Correlation coefficient: 0.52\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as es_relevance increases, fc_coverage tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "es_relevance vs fc_support:\n",
      "Correlation coefficient: 0.54\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as es_relevance increases, fc_support tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "es_effectiveness vs fc_scale5_overall:\n",
      "Correlation coefficient: 0.47\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as es_effectiveness increases, fc_scale5_overall tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "es_effectiveness vs fc_coverage:\n",
      "Correlation coefficient: 0.52\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as es_effectiveness increases, fc_coverage tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "es_effectiveness vs fc_support:\n",
      "Correlation coefficient: 0.56\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as es_effectiveness increases, fc_support tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "es_logical_connection vs fc_scale5_overall:\n",
      "Correlation coefficient: 0.46\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as es_logical_connection increases, fc_scale5_overall tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "es_logical_connection vs fc_coverage:\n",
      "Correlation coefficient: 0.50\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as es_logical_connection increases, fc_coverage tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "es_logical_connection vs fc_support:\n",
      "Correlation coefficient: 0.55\n",
      "P-value: 0.0000\n",
      "Interpretation: Positive correlation - as es_logical_connection increases, fc_support tends to increase\n",
      "Strength: Strong correlation\n",
      "\n",
      "Significant correlations between Evidence Synthesis and Process Evaluation:\n",
      "--------------------------------------------------\n",
      "\n",
      "es_overall vs proc_explainability:\n",
      "Correlation coefficient: 0.35\n",
      "P-value: 0.0015\n",
      "Interpretation: Positive correlation - as es_overall increases, proc_explainability tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "es_overall vs proc_transparency:\n",
      "Correlation coefficient: 0.28\n",
      "P-value: 0.0244\n",
      "Interpretation: Positive correlation - as es_overall increases, proc_transparency tends to increase\n",
      "Strength: Weak correlation\n",
      "\n",
      "es_relevance vs proc_explainability:\n",
      "Correlation coefficient: 0.28\n",
      "P-value: 0.0081\n",
      "Interpretation: Positive correlation - as es_relevance increases, proc_explainability tends to increase\n",
      "Strength: Weak correlation\n",
      "\n",
      "es_relevance vs proc_transparency:\n",
      "Correlation coefficient: 0.25\n",
      "P-value: 0.0401\n",
      "Interpretation: Positive correlation - as es_relevance increases, proc_transparency tends to increase\n",
      "Strength: Weak correlation\n",
      "\n",
      "es_effectiveness vs proc_scale5_overall:\n",
      "Correlation coefficient: 0.26\n",
      "P-value: 0.0461\n",
      "Interpretation: Positive correlation - as es_effectiveness increases, proc_scale5_overall tends to increase\n",
      "Strength: Weak correlation\n",
      "\n",
      "es_effectiveness vs proc_explainability:\n",
      "Correlation coefficient: 0.33\n",
      "P-value: 0.0032\n",
      "Interpretation: Positive correlation - as es_effectiveness increases, proc_explainability tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "es_effectiveness vs proc_transparency:\n",
      "Correlation coefficient: 0.26\n",
      "P-value: 0.0311\n",
      "Interpretation: Positive correlation - as es_effectiveness increases, proc_transparency tends to increase\n",
      "Strength: Weak correlation\n",
      "\n",
      "es_logical_connection vs proc_scale5_overall:\n",
      "Correlation coefficient: 0.24\n",
      "P-value: 0.0450\n",
      "Interpretation: Positive correlation - as es_logical_connection increases, proc_scale5_overall tends to increase\n",
      "Strength: Weak correlation\n",
      "\n",
      "es_logical_connection vs proc_explainability:\n",
      "Correlation coefficient: 0.38\n",
      "P-value: 0.0003\n",
      "Interpretation: Positive correlation - as es_logical_connection increases, proc_explainability tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "es_logical_connection vs proc_transparency:\n",
      "Correlation coefficient: 0.27\n",
      "P-value: 0.0173\n",
      "Interpretation: Positive correlation - as es_logical_connection increases, proc_transparency tends to increase\n",
      "Strength: Weak correlation\n",
      "\n",
      "Significant correlations between Final Conclusion and Process Evaluation:\n",
      "--------------------------------------------------\n",
      "\n",
      "fc_coverage vs proc_scale5_overall:\n",
      "Correlation coefficient: 0.29\n",
      "P-value: 0.0436\n",
      "Interpretation: Positive correlation - as fc_coverage increases, proc_scale5_overall tends to increase\n",
      "Strength: Weak correlation\n",
      "\n",
      "fc_coverage vs proc_explainability:\n",
      "Correlation coefficient: 0.31\n",
      "P-value: 0.0169\n",
      "Interpretation: Positive correlation - as fc_coverage increases, proc_explainability tends to increase\n",
      "Strength: Moderate correlation\n",
      "\n",
      "fc_coverage vs proc_transparency:\n",
      "Correlation coefficient: 0.28\n",
      "P-value: 0.0169\n",
      "Interpretation: Positive correlation - as fc_coverage increases, proc_transparency tends to increase\n",
      "Strength: Weak correlation\n",
      "\n",
      "fc_support vs proc_transparency:\n",
      "Correlation coefficient: 0.26\n",
      "P-value: 0.0370\n",
      "Interpretation: Positive correlation - as fc_support increases, proc_transparency tends to increase\n",
      "Strength: Weak correlation\n"
     ]
    }
   ],
   "execution_count": 248
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T23:21:49.948215Z",
     "start_time": "2025-02-02T23:21:49.893993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# performance by claim type\n",
    "import scipy\n",
    "\n",
    "claims_df = pd.read_csv(f\"{output_dir}/claims.csv\")\n",
    "cd_df = pd.read_csv(f\"{output_dir}/processed/cd_process_phase_1.csv\")\n",
    "es_df = pd.read_csv(f\"{output_dir}/processed/es_process_phase_1.csv\")\n",
    "fc_df = pd.read_csv(f\"{output_dir}/processed/fc_process_phase_1.csv\")\n",
    "\n",
    "def get_claim_stats(df, claim_number, metric_identifier):\n",
    "    claim_cols = [col for col in df.columns if f'claim{claim_number}' in col and metric_identifier in col]\n",
    "    if claim_cols:\n",
    "        claim_data = df[claim_cols].values.ravel()\n",
    "        return {\n",
    "            'mean': np.mean(claim_data),\n",
    "            'std': np.std(claim_data),\n",
    "            'median': np.median(claim_data),\n",
    "            'n': len(claim_data),\n",
    "            'ci': scipy.stats.t.interval(confidence=0.95, \n",
    "                                 df=len(claim_data)-1,\n",
    "                                 loc=np.mean(claim_data),\n",
    "                                 scale=scipy.stats.sem(claim_data))\n",
    "        }\n",
    "    return None\n",
    "\n",
    "metrics = {\n",
    "    'CD': {\n",
    "        'coverage': 'coverage',\n",
    "        'relevance': 'relevance',\n",
    "        'formulation': 'formulation',\n",
    "        'explainability': 'explainability'\n",
    "    },\n",
    "    'ES': {\n",
    "        'relevance': 'relevance',\n",
    "        'effectiveness': 'effectiveness',\n",
    "        'logical_connection': 'logical_connection'\n",
    "    },\n",
    "    'FC': {\n",
    "        'coverage': 'coverage',\n",
    "        'support': 'support',\n",
    "        'alignment': 'allignment',\n",
    "        'choice': 'choice'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Analyze each claim\n",
    "claim_analysis = []\n",
    "for idx, claim in claims_df.iterrows():\n",
    "    claim_num = claim['number']\n",
    "    claim_data = {\n",
    "        'claim_number': claim_num,\n",
    "        'text': claim['text'],\n",
    "        'political_stance': claim['political_stance']\n",
    "    }\n",
    "    \n",
    "    # Get CD metrics\n",
    "    for metric_name, metric_id in metrics['CD'].items():\n",
    "        stats = get_claim_stats(cd_df, claim_num, metric_id)\n",
    "        if stats:\n",
    "            claim_data[f'cd_{metric_name}_mean'] = stats['mean']\n",
    "            claim_data[f'cd_{metric_name}_ci_lower'] = stats['ci'][0]\n",
    "            claim_data[f'cd_{metric_name}_ci_upper'] = stats['ci'][1]\n",
    "    \n",
    "    # Get ES metrics\n",
    "    for metric_name, metric_id in metrics['ES'].items():\n",
    "        stats = get_claim_stats(es_df, claim_num, metric_id)\n",
    "        if stats:\n",
    "            claim_data[f'es_{metric_name}_mean'] = stats['mean']\n",
    "            claim_data[f'es_{metric_name}_ci_lower'] = stats['ci'][0]\n",
    "            claim_data[f'es_{metric_name}_ci_upper'] = stats['ci'][1]\n",
    "    \n",
    "    # Get FC metrics\n",
    "    for metric_name, metric_id in metrics['FC'].items():\n",
    "        stats = get_claim_stats(fc_df, claim_num, metric_id)\n",
    "        if stats:\n",
    "            claim_data[f'fc_{metric_name}_mean'] = stats['mean']\n",
    "            claim_data[f'fc_{metric_name}_ci_lower'] = stats['ci'][0]\n",
    "            claim_data[f'fc_{metric_name}_ci_upper'] = stats['ci'][1]\n",
    "    \n",
    "    claim_analysis.append(claim_data)\n",
    "\n",
    "# Convert to DataFrame\n",
    "claims_analysis_df = pd.DataFrame(claim_analysis)\n",
    "\n",
    "# Save detailed analysis\n",
    "claims_analysis_df.to_csv(f\"{output_dir}/processed/claims_analysis.csv\", index=False)\n",
    "\n",
    "# Analyze by political stance\n",
    "def print_stance_analysis(df, metric_prefix, metric_name):\n",
    "    print(f\"\\n{metric_prefix.upper()} - {metric_name}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for stance in df['political_stance'].unique():\n",
    "        stance_data = df[df['political_stance'] == stance]\n",
    "        col_name = f\"{metric_prefix}_{metric_name}_mean\"\n",
    "        mean = stance_data[col_name].mean()\n",
    "        ci = scipy.stats.t.interval(confidence=0.95,\n",
    "                            df=len(stance_data)-1,\n",
    "                            loc=mean,\n",
    "                            scale=scipy.stats.sem(stance_data[col_name]))\n",
    "        print(f\"{stance}:\")\n",
    "        print(f\"Mean: {mean:.2f} (95% CI: [{ci[0]:.2f}, {ci[1]:.2f}])\")\n",
    "        print(f\"N = {len(stance_data)}\")\n",
    "\n",
    "print(\"\\nAnalysis by Political Stance:\")\n",
    "for phase, phase_metrics in metrics.items():\n",
    "    for metric_name in phase_metrics.keys():\n",
    "        print_stance_analysis(claims_analysis_df, phase.lower(), metric_name)\n",
    "\n",
    "print(\"\\nOverall Claim Performance:\")\n",
    "print(\"-\" * 50)\n",
    "for idx, claim in claims_analysis_df.iterrows():\n",
    "    print(f\"\\nClaim {claim['claim_number']} ({claim['political_stance']}):\")\n",
    "    print(f\"Text: {claim['text']}\")\n",
    "    \n",
    "    # Print averages for each phase\n",
    "    for phase in ['cd', 'es', 'fc']:\n",
    "        phase_cols = [col for col in claims_analysis_df.columns if col.startswith(f\"{phase}_\") and col.endswith(\"_mean\")]\n",
    "        if phase_cols:\n",
    "            phase_mean = claim[phase_cols].mean()\n",
    "            print(f\"{phase.upper()} Average: {phase_mean:.2f}\")"
   ],
   "id": "41ecaa3b0ee5691f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analysis by Political Stance:\n",
      "\n",
      "CD - coverage\n",
      "--------------------------------------------------\n",
      "pro_republican:\n",
      "Mean: 3.87 (95% CI: [2.64, 5.11])\n",
      "N = 2\n",
      "pro_democrat:\n",
      "Mean: 3.88 (95% CI: [nan, nan])\n",
      "N = 1\n",
      "neutral:\n",
      "Mean: 3.98 (95% CI: [3.67, 4.28])\n",
      "N = 2\n",
      "\n",
      "CD - relevance\n",
      "--------------------------------------------------\n",
      "pro_republican:\n",
      "Mean: 3.83 (95% CI: [2.71, 4.94])\n",
      "N = 2\n",
      "pro_democrat:\n",
      "Mean: 3.83 (95% CI: [nan, nan])\n",
      "N = 1\n",
      "neutral:\n",
      "Mean: 3.90 (95% CI: [3.10, 4.70])\n",
      "N = 2\n",
      "\n",
      "CD - formulation\n",
      "--------------------------------------------------\n",
      "pro_republican:\n",
      "Mean: 3.71 (95% CI: [1.80, 5.63])\n",
      "N = 2\n",
      "pro_democrat:\n",
      "Mean: 3.78 (95% CI: [nan, nan])\n",
      "N = 1\n",
      "neutral:\n",
      "Mean: 3.81 (95% CI: [3.26, 4.37])\n",
      "N = 2\n",
      "\n",
      "CD - explainability\n",
      "--------------------------------------------------\n",
      "pro_republican:\n",
      "Mean: 3.87 (95% CI: [2.08, 5.66])\n",
      "N = 2\n",
      "pro_democrat:\n",
      "Mean: 3.81 (95% CI: [nan, nan])\n",
      "N = 1\n",
      "neutral:\n",
      "Mean: 3.92 (95% CI: [3.55, 4.29])\n",
      "N = 2\n",
      "\n",
      "ES - relevance\n",
      "--------------------------------------------------\n",
      "pro_republican:\n",
      "Mean: 3.52 (95% CI: [0.37, 6.67])\n",
      "N = 2\n",
      "pro_democrat:\n",
      "Mean: 3.69 (95% CI: [nan, nan])\n",
      "N = 1\n",
      "neutral:\n",
      "Mean: 3.83 (95% CI: [3.46, 4.20])\n",
      "N = 2\n",
      "\n",
      "ES - effectiveness\n",
      "--------------------------------------------------\n",
      "pro_republican:\n",
      "Mean: 3.51 (95% CI: [0.92, 6.11])\n",
      "N = 2\n",
      "pro_democrat:\n",
      "Mean: 3.51 (95% CI: [nan, nan])\n",
      "N = 1\n",
      "neutral:\n",
      "Mean: 3.75 (95% CI: [2.14, 5.35])\n",
      "N = 2\n",
      "\n",
      "ES - logical_connection\n",
      "--------------------------------------------------\n",
      "pro_republican:\n",
      "Mean: 3.61 (95% CI: [1.82, 5.40])\n",
      "N = 2\n",
      "pro_democrat:\n",
      "Mean: 3.68 (95% CI: [nan, nan])\n",
      "N = 1\n",
      "neutral:\n",
      "Mean: 3.72 (95% CI: [3.47, 3.97])\n",
      "N = 2\n",
      "\n",
      "FC - coverage\n",
      "--------------------------------------------------\n",
      "pro_republican:\n",
      "Mean: 3.57 (95% CI: [1.04, 6.10])\n",
      "N = 2\n",
      "pro_democrat:\n",
      "Mean: 3.34 (95% CI: [nan, nan])\n",
      "N = 1\n",
      "neutral:\n",
      "Mean: 3.77 (95% CI: [2.60, 4.94])\n",
      "N = 2\n",
      "\n",
      "FC - support\n",
      "--------------------------------------------------\n",
      "pro_republican:\n",
      "Mean: 3.43 (95% CI: [-0.08, 6.95])\n",
      "N = 2\n",
      "pro_democrat:\n",
      "Mean: 3.45 (95% CI: [nan, nan])\n",
      "N = 1\n",
      "neutral:\n",
      "Mean: 3.76 (95% CI: [3.45, 4.07])\n",
      "N = 2\n",
      "\n",
      "FC - alignment\n",
      "--------------------------------------------------\n",
      "pro_republican:\n",
      "Mean: 2.75 (95% CI: [1.51, 3.98])\n",
      "N = 2\n",
      "pro_democrat:\n",
      "Mean: 2.54 (95% CI: [nan, nan])\n",
      "N = 1\n",
      "neutral:\n",
      "Mean: 2.95 (95% CI: [-0.20, 6.09])\n",
      "N = 2\n",
      "\n",
      "FC - choice\n",
      "--------------------------------------------------\n",
      "pro_republican:\n",
      "Mean: 3.79 (95% CI: [3.66, 3.91])\n",
      "N = 2\n",
      "pro_democrat:\n",
      "Mean: 3.54 (95% CI: [nan, nan])\n",
      "N = 1\n",
      "neutral:\n",
      "Mean: 3.66 (95% CI: [2.18, 5.14])\n",
      "N = 2\n",
      "\n",
      "Overall Claim Performance:\n",
      "--------------------------------------------------\n",
      "\n",
      "Claim 1 (pro_republican):\n",
      "Text: Says Ford agreed to invest $900 million at an Ohio plant because Donald Trump lowered taxes and is now moving the project to Mexico because Joe Biden is increasing taxes.\n",
      "CD Average: 3.94\n",
      "ES Average: 3.74\n",
      "FC Average: 3.53\n",
      "\n",
      "Claim 2 (pro_democrat):\n",
      "Text: The Biden administration inherited gains of 50,000 jobs a month. We're now finally back to 500,000 jobs a month. We inherited a country where 4,000 people a day were dying from Covid. That's now down 75%.\n",
      "CD Average: 3.82\n",
      "ES Average: 3.63\n",
      "FC Average: 3.22\n",
      "\n",
      "Claim 3 (neutral):\n",
      "Text: Officials recommend that women who get one of these (COVID-19) shots should absolutely not get pregnant for at least the first two months after they've been injected.\n",
      "CD Average: 3.93\n",
      "ES Average: 3.81\n",
      "FC Average: 3.66\n",
      "\n",
      "Claim 4 (pro_republican):\n",
      "Text: Joe Biden and Kamala Harris government-run health care plan could lead to hospitals being closed, put Medicare coverage at risk, and give benefits to illegal immigrants.\n",
      "CD Average: 3.70\n",
      "ES Average: 3.35\n",
      "FC Average: 3.24\n",
      "\n",
      "Claim 5 (neutral):\n",
      "Text: Wisconsin was the last state to start paying COVID-related federal unemployment benefits.\n",
      "CD Average: 3.87\n",
      "ES Average: 3.72\n",
      "FC Average: 3.42\n"
     ]
    }
   ],
   "execution_count": 243
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9767477934019fcb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
